@article{abeTrajectoryPlanningFlexible2011,
  title = {Trajectory Planning for Flexible {{Cartesian}} Robot Manipulator by Using Artificial Neural Network: Numerical Simulation and Experimental Verification},
  shorttitle = {Trajectory Planning for Flexible {{Cartesian}} Robot Manipulator by Using Artificial Neural Network},
  author = {Abe, Akira},
  date = {2011-09},
  journaltitle = {Robotica},
  shortjournal = {Robotica},
  volume = {29},
  number = {5},
  pages = {797--804},
  issn = {0263-5747, 1469-8668},
  doi = {10.1017/S0263574710000767},
  url = {https://www.cambridge.org/core/product/identifier/S0263574710000767/type/journal_article},
  urldate = {2022-10-23},
  abstract = {This paper presents a novel trajectory planning method for a flexible Cartesian robot manipulator in a point-to-point motion. In order to obtain an exact mathematical model, the parameters of the equation of motion are determined from an identification experiment. An artificial neural network is employed to generate the desired base position, and then, a particle swarm optimization technique is used as the learning algorithm, in which the sum of the displacements of the manipulator is chosen as the objective function. We show that the residual vibrations of the manipulator can be suppressed by minimizing the displacement of the manipulator. The effectiveness and validity of the proposed method are demonstrated by comparing the simulation and experimental results.},
  langid = {english},
  file = {/home/julin/Zotero/storage/MMLDZZHN/Abe - 2011 - Trajectory planning for flexible Cartesian robot m.pdf}
}

@inproceedings{adiyatovNovelRRTbasedAlgorithm2017,
  title = {A Novel {{RRT-based}} Algorithm for Motion Planning in {{Dynamic}} Environments},
  booktitle = {2017 {{IEEE International Conference}} on {{Mechatronics}} and {{Automation}} ({{ICMA}})},
  author = {Adiyatov, Olzhas and Varol, Huseyin Atakan},
  date = {2017-08},
  pages = {1416--1421},
  issn = {2152-744X},
  doi = {10.1109/ICMA.2017.8016024},
  abstract = {Sampling-based motion planning has become a powerful framework for solving complex robotic motion-planning tasks. Despite the introduction of a multitude of algorithms, most of these deal with the static case involving non-moving obstacles. In this work, we are extending our memory efficient RRT*FN algorithm to dynamic scenarios. Specifically, we retain the useful parts of the tree (the data structure storing the motion plan information) after a dynamic obstacle invalidates the solution path. We then employ two greedy heuristics to repair the solution instead of running the whole motion planning process from scratch. We call this new algorithm, RRT*FN-Dynamic (RRT*FND). To compare our method to the state-of-the-art motion planners, RRT* and RRT*FN, we conducted an extensive set of benchmark experiments in dynamic environments using two robot models: a non-holonomic mobile robot and an industrial manipulator. The results of these experiments show that RRT*FND finds the solution path in shorter time in most of the cases and verifies the efficacy of it in dynamic settings.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Mechatronics}} and {{Automation}} ({{ICMA}})},
  keywords = {Cost function,dynamic environments,Dynamics,Heuristic algorithms,motion planning,Path planning,Planning,rapidly-exploring random trees,Robots,sampling-based methods,Trajectory},
  file = {/home/julin/Zotero/storage/R2WWMHHQ/8016024.html}
}

@inproceedings{adiyatovNovelRRTbasedAlgorithm2017a,
  title = {A Novel {{RRT-based}} Algorithm for Motion Planning in {{Dynamic}} Environments},
  booktitle = {2017 {{IEEE International Conference}} on {{Mechatronics}} and {{Automation}} ({{ICMA}})},
  author = {Adiyatov, Olzhas and Varol, Huseyin Atakan},
  date = {2017-08},
  pages = {1416--1421},
  issn = {2152-744X},
  doi = {10.1109/ICMA.2017.8016024},
  abstract = {Sampling-based motion planning has become a powerful framework for solving complex robotic motion-planning tasks. Despite the introduction of a multitude of algorithms, most of these deal with the static case involving non-moving obstacles. In this work, we are extending our memory efficient RRT*FN algorithm to dynamic scenarios. Specifically, we retain the useful parts of the tree (the data structure storing the motion plan information) after a dynamic obstacle invalidates the solution path. We then employ two greedy heuristics to repair the solution instead of running the whole motion planning process from scratch. We call this new algorithm, RRT*FN-Dynamic (RRT*FND). To compare our method to the state-of-the-art motion planners, RRT* and RRT*FN, we conducted an extensive set of benchmark experiments in dynamic environments using two robot models: a non-holonomic mobile robot and an industrial manipulator. The results of these experiments show that RRT*FND finds the solution path in shorter time in most of the cases and verifies the efficacy of it in dynamic settings.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Mechatronics}} and {{Automation}} ({{ICMA}})},
  keywords = {Cost function,dynamic environments,Dynamics,Heuristic algorithms,motion planning,Path planning,Planning,rapidly-exploring random trees,Robots,sampling-based methods,Trajectory},
  file = {/home/julin/Zotero/storage/5RXM6F3R/Adiyatov und Varol - 2017 - A novel RRT-based algorithm for motion planning in.pdf;/home/julin/Zotero/storage/3W8G7W4G/8016024.html}
}

@software{AdversarialDriving2022,
  title = {Adversarial {{Driving}}},
  date = {2022-09-15T07:49:35Z},
  origdate = {2019-11-05T20:15:50Z},
  url = {https://github.com/sisl/AdversarialDriving.jl},
  urldate = {2022-10-23},
  abstract = {Adversarial driving simulator for testing safety validation algorithms},
  organization = {{Stanford Intelligent Systems Laboratory}}
}

@incollection{akazakiFalsificationCyberPhysicalSystems2018,
  title = {Falsification of {{Cyber-Physical Systems Using Deep Reinforcement Learning}}},
  author = {Akazaki, Takumi and Liu, Shuang and Yamagata, Yoriyuki and Duan, Yihai and Hao, Jianye},
  date = {2018},
  volume = {10951},
  eprint = {1805.00200},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {456--465},
  doi = {10.1007/978-3-319-95582-7_27},
  url = {http://arxiv.org/abs/1805.00200},
  urldate = {2022-10-24},
  abstract = {With the rapid development of software and distributed computing, Cyber-Physical Systems (CPS) are widely adopted in many application areas, e.g., smart grid, autonomous automobile. It is difficult to detect defects in CPS models due to the complexities involved in the software and physical systems. To find defects in CPS models efficiently, robustness guided falsification of CPS is introduced. Existing methods use several optimization techniques to generate counterexamples, which falsify the given properties of a CPS. However those methods may require a large number of simulation runs to find the counterexample and is far from practical. In this work, we explore state-of-the-art Deep Reinforcement Learning (DRL) techniques to reduce the number of simulation runs required to find such counterexamples. We report our method and the preliminary evaluation results.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {/home/julin/Zotero/storage/ZLX9G2FM/Akazaki et al. - 2018 - Falsification of Cyber-Physical Systems Using Deep.pdf;/home/julin/Zotero/storage/597L26KY/1805.html}
}

@article{al-khayytCreatingPointsLinear2018,
  title = {Creating {{Through Points}} in {{Linear Function}} with {{Parabolic Blends Path}} by {{Optimization Method}}},
  author = {Al-khayyt, Saad Zaghlul Saeed},
  date = {2018-04-09},
  journaltitle = {Al-Khwarizmi Engineering Journal},
  volume = {14},
  number = {1},
  pages = {77--89},
  issn = {2312-0789},
  doi = {10.22153/kej.2018.10.005},
  url = {https://alkej.uobaghdad.edu.iq/index.php/alkej/article/view/116},
  urldate = {2022-11-14},
  abstract = {أن مسار القطعة الخطية المندمجة مع مسار القطع المكافئ ينحرف عن المسار المخطط\&nbsp; و هو مقيد بقيمة تعجيل\&nbsp; يجب ان تكون كبيرة بما فيه الكفاية. من ناحية أخرى، التعامل مع مسار القطعة الخطية المندمجة مع مسار القطع المكافئ في المقالات الموجودة حاليا حول الموضوع غير قابل للتطبيق مباشرة على المسارات الحركية. في هذا العمل، اقترح تعديل على مسار القطعة الخطية المندمجة مع مسار القطع المكافئ\&nbsp; و تم تعشيقه مع أمثلة جسيم السرب لتوليد نقاط عبر المسار. أن الطرق السابقة التي تعتمد على فرضية\&nbsp; التوزيع المتساوي لزمن مسار القطع المكافئ حول نقطة المسار، استبدلت بمعاملات مقترحة لحساب الفترة الزمنية لمسار القطعة الخطية. هذه المعاملات هي دوال من السرع بين نقاط المسار. أن مسار القطعة الخطية المندمجة مع مسار القطع المكافئ المطور يستخدم السرع بين نقاط المسار التي تستحصل بطريقة امثلية جسيم السرب لإجبار مدبر الروبوت على المرور خلال نقاط المسار المحددة أخذا بنظر الاعتبار تقيدي السرعة و التعجيل للروبوت المستعمل. كذلك تم اشتقاق علاقات لتصحيح السرعة و معادلات لحساب السرعة الفعلية. نتائج المحاكاة العددية أظهرت ان تعشيق المسار الخطي المندمج مع مسار القطع المكافئ المطور مع أمثلة جسيم الحشد يعمل بشكل جيد في الاختبارات. وان هذه الطريقة المقترحة بسيطة جدا و يمكن ان تستعمل لتخطيط المسار مباشرة و غير ضروري فيها استخدام قيمة تعجيل كبيرة.},
  langid = {english},
  file = {/home/julin/Zotero/storage/5US3MXEI/Al-khayyt - 2018 - Creating Through Points in Linear Function with Pa.pdf}
}

@article{altmanIntroductionKernelNearestNeighbor1992,
  title = {An {{Introduction}} to {{Kernel}} and {{Nearest-Neighbor Nonparametric Regression}}},
  author = {Altman, N. S.},
  date = {1992-08},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {46},
  number = {3},
  pages = {175--185},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.1992.10475879},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1992.10475879},
  urldate = {2022-07-26},
  langid = {english},
  file = {/home/julin/Zotero/storage/PAGWCM9I/Altman - 1992 - An Introduction to Kernel and Nearest-Neighbor Non.pdf}
}

@online{amineQLearningAlgorithmExplanation2020,
  title = {Q-{{Learning Algorithm}}: {{From Explanation}} to {{Implementation}}},
  shorttitle = {Q-{{Learning Algorithm}}},
  author = {Amine, Amrani},
  date = {2020-12-19T23:19:12},
  url = {https://towardsdatascience.com/q-learning-algorithm-from-explanation-to-implementation-cdbeda2ea187},
  urldate = {2022-12-05},
  abstract = {In my today’s medium post, I will teach how to implement the Q-Learning algorithm. But before that, I will first explain the idea behind…},
  langid = {english},
  organization = {{Medium}},
  file = {/home/julin/Zotero/storage/GKIJ2Z9M/q-learning-algorithm-from-explanation-to-implementation-cdbeda2ea187.html}
}

@article{arulkumaranDeepReinforcementLearning2017,
  title = {Deep {{Reinforcement Learning}}: {{A Brief Survey}}},
  shorttitle = {Deep {{Reinforcement Learning}}},
  author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  date = {2017-11},
  journaltitle = {IEEE Signal Processing Magazine},
  volume = {34},
  number = {6},
  pages = {26--38},
  issn = {1558-0792},
  doi = {10.1109/MSP.2017.2743240},
  abstract = {Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higher-level understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels. DRL algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of RL, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep RL, including the deep Q-network (DQN), trust region policy optimization (TRPO), and asynchronous advantage actor critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via RL. To conclude, we describe several current areas of research within the field.},
  eventtitle = {{{IEEE Signal Processing Magazine}}},
  keywords = {Artificial intelligence,Learning (artificial intelligence),Machine learning,Neural networks,Signal processing algorithms,Visualization},
  file = {/home/julin/Zotero/storage/9MQVGEE5/Arulkumaran et al. - 2017 - Deep Reinforcement Learning A Brief Survey.pdf;/home/julin/Zotero/storage/EYS2J8Y2/8103164.html}
}

@article{ataOPTIMALTRAJECTORYPLANNING2007,
  title = {{{OPTIMAL TRAJECTORY PLANNING OF MANIPULATORS}}: {{A REVIEW}}},
  shorttitle = {{{OPTIMAL TRAJECTORY PLANNING OF MANIPULATORS}}},
  author = {ATA, Atef},
  date = {2007-04-01},
  journaltitle = {Journal of Engineering Science and Technology},
  shortjournal = {Journal of Engineering Science and Technology},
  volume = {2},
  abstract = {Optimal motion planning is very important to the operation of robot manipulators. Its main target is the generation of a trajectory from start to goal that satisfies objectives, such as minimizing path traveling distance or time interval, lowest energy consumption or obstacle avoidance and satisfying the robot’s kinematics and dynamics. Review, discussion and analysis of optimization techniques to find the optimal trajectory either in Cartesian space or joint space are presented and investigated. Optimal trajectory selection approaches such as kinematics and dynamics techniques with various constraints are presented and explained. Although the kinematics approach is simple and straight forward, it will experience some problems in implementation because of lack of Inertia and torque constraints. The application of Genetic Algorithms to find the optimal trajectory of manipulators especially in the obstacle avoidance is also highlighted. Combining the Genetic Algorithms with other classical optimization methods proves to have better performance as a hybrid optimization technique.},
  file = {/home/julin/Zotero/storage/3QAKAP8K/ATA - 2007 - OPTIMAL TRAJECTORY PLANNING OF MANIPULATORS A REV.pdf}
}

@article{auerFinitetimeAnalysisMultiarmed2002,
  title = {Finite-Time {{Analysis}} of the {{Multiarmed Bandit Problem}}},
  author = {Auer, Peter and Cesa-Bianchi, Nicolò and Fischer, Paul},
  date = {2002-05-01},
  journaltitle = {Machine Learning},
  shortjournal = {Machine Learning},
  volume = {47},
  number = {2},
  pages = {235--256},
  issn = {1573-0565},
  doi = {10.1023/A:1013689704352},
  url = {https://doi.org/10.1023/A:1013689704352},
  urldate = {2022-12-05},
  abstract = {Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support.},
  langid = {english},
  keywords = {adaptive allocation rules,bandit problems,finite horizon regret},
  file = {/home/julin/Zotero/storage/RXJH22LM/Auer et al. - 2002 - Finite-time Analysis of the Multiarmed Bandit Prob.pdf}
}

@online{AvailablePlanners,
  title = {Available {{Planners}}},
  url = {http://ompl.kavrakilab.org/planners.html},
  urldate = {2022-11-14},
  file = {/home/julin/Zotero/storage/TJ9ZXWFQ/planners.html}
}

@article{bertsekasDynamicProgrammingOptimal,
  title = {Dynamic {{Programming}} and {{Optimal Control}} 3rd {{Edition}}, {{Volume II}}},
  author = {Bertsekas, Dimitri P},
  pages = {233},
  langid = {english},
  file = {/home/julin/Zotero/storage/FKDX5ABU/Bertsekas - Dynamic Programming and Optimal Control 3rd Editio.pdf}
}

@book{biagiottiTrajectoryPlanningAutomatic2008,
  title = {Trajectory {{Planning}} for {{Automatic Machines}} and {{Robots}}},
  author = {Biagiotti, Luigi and Melchiorri, Claudio},
  date = {2008-10-23},
  eprint = {FiX1ceRT5zoC},
  eprinttype = {googlebooks},
  publisher = {{Springer Science \& Business Media}},
  abstract = {This book deals with the problems related to planning motion laws and t- jectories for the actuation system of automatic machines, in particular for those based on electric drives, and robots. The problem of planning suitable trajectories is relevant not only for the proper use of these machines, in order to avoid undesired e?ects such as vibrations or even damages on the mech- ical structure, but also in some phases of their design and in the choice and sizing of the actuators. This is particularly true now that the concept of “el- tronic cams” has replaced, in the design of automatic machines, the classical approach based on “mechanical cams”. The choice of a particular trajectory has direct and relevant implications on several aspects of the design and use of an automatic machine, like the dimensioning of the actuators and of the reduction gears, the vibrations and e?orts generated on the machine and on the load, the tracking errors during the motion execution. For these reasons, in order to understand and appreciate the peculiarities of the di?erent techniques available for trajectory planning, besides the ma- ematical aspects of their implementation also a detailed analysis in the time and frequency domains, a comparison of their main properties under di?erent points of view, and general considerations related to their practical use are reported.},
  isbn = {978-3-540-85629-0},
  langid = {english},
  pagetotal = {515},
  keywords = {Computers / Artificial Intelligence / General,Technology & Engineering / Automation,Technology & Engineering / Manufacturing,Technology & Engineering / Robotics}
}

@article{brattonAlvinKennedyGreensboro,
  title = {Alvin {{P}}. {{Kennedy}}, {{Greensboro}}, {{N}}.{{C}}.; {{Zdravko Jezic}}, {{Midland}}, {{Mich}}.; {{Larry}}},
  author = {Bratton, D and Lan, Eckel and Perettie, Donald J},
  pages = {23},
  abstract = {A laminate has at least two layers, at least one of which comprises a polymer having more than one perfluorocy clobutane group. Such polymers impart qualities of envi ronmental or protection, chemical and solvent resistance, hydrolytic stability, lubricity, low dielectric, hydrostatic stability, weatherability, flame resistance, chemical resistance, hydrolytic stability, lubricity, environmental protection, scratch resistance, solvent resistance, surface passivation, water repellancy, lower surface refractive index, lower surface coefficient of friction, fluid barrier properties, oil repellancy, thermal stability, and/or reduced moisture pick-up. Additionally, the coatings are optically clear, easy to apply either neat, in a solventor otherwise, have relatively low cure temperatures for their temperature resistance, and exhibit insulating and planarizing capabilities.},
  langid = {english},
  file = {/home/julin/Zotero/storage/36S4U837/Bratton et al. - Alvin P. Kennedy, Greensboro, N.C.\; Zdravko Jezic,.pdf}
}

@article{browneSurveyMonteCarlo2012,
  title = {A {{Survey}} of {{Monte Carlo Tree Search Methods}}},
  author = {Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  date = {2012-03},
  journaltitle = {IEEE Transactions on Computational Intelligence and AI in Games},
  volume = {4},
  number = {1},
  pages = {1--43},
  issn = {1943-0698},
  doi = {10.1109/TCIAIG.2012.2186810},
  abstract = {Monte Carlo tree search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarize the results from the key game and nongame domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.},
  eventtitle = {{{IEEE Transactions}} on {{Computational Intelligence}} and {{AI}} in {{Games}}},
  keywords = {Artificial intelligence,Artificial intelligence (AI),bandit-based methods,computer Go,Computers,Decision theory,game search,Game theory,Games,Markov processes,Monte Carlo methods,Monte Carlo tree search (MCTS),upper confidence bounds (UCB),upper confidence bounds for trees (UCT)},
  file = {/home/julin/Zotero/storage/VX3DSFEI/Browne et al. - 2012 - A Survey of Monte Carlo Tree Search Methods.pdf;/home/julin/Zotero/storage/B2WYKKD9/6145622.html}
}

@online{brownleeHowDevelopPix2Pix2019,
  title = {How to {{Develop}} a {{Pix2Pix GAN}} for {{Image-to-Image Translation}}},
  author = {Brownlee, Jason},
  date = {2019-08-01T19:00:04+00:00},
  url = {https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/},
  urldate = {2020-10-30},
  abstract = {The Pix2Pix Generative Adversarial Network, or GAN, is an approach to training a deep convolutional neural network for image-to-image translation tasks. The careful configuration of architecture as a type of image-conditional GAN allows for both the generation of large images compared to prior GAN models (e.g. such as 256×256 pixels) and the capability of performing […]},
  langid = {american},
  organization = {{Machine Learning Mastery}},
  file = {/home/julin/Zotero/storage/I2EXJK6G/how-to-develop-a-pix2pix-gan-for-image-to-image-translation.html}
}

@online{brownleeHowEvaluateGenerative2019,
  title = {How to {{Evaluate Generative Adversarial Networks}}},
  author = {Brownlee, Jason},
  date = {2019-08-25T19:00:34+00:00},
  url = {https://machinelearningmastery.com/how-to-evaluate-generative-adversarial-networks/},
  urldate = {2021-01-06},
  abstract = {Generative adversarial networks, or GANs for short, are an effective deep learning approach for developing generative models. Unlike other deep learning neural network models that are trained with a loss function until convergence, a GAN generator model is trained using a second model called a discriminator that learns to classify images as real or generated. […]},
  langid = {american},
  organization = {{Machine Learning Mastery}},
  file = {/home/julin/Zotero/storage/FRJWSSI9/how-to-evaluate-generative-adversarial-networks.html}
}

@inproceedings{burgetBIRRTEfficient2016,
  title = {{{BI}} {\textsuperscript{2}} {{RRT}}: {{An}} Efficient Sampling-Based Path Planning Framework for Task-Constrained Mobile Manipulation},
  shorttitle = {{{BI}} {\textsuperscript{2}} {{RRT}}},
  booktitle = {2016 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Burget, Felix and Bennewitz, Maren and Burgard, Wolfram},
  date = {2016-10},
  pages = {3714--3721},
  publisher = {{IEEE}},
  location = {{Daejeon, Korea (South)}},
  doi = {10.1109/IROS.2016.7759547},
  url = {https://ieeexplore.ieee.org/document/7759547/},
  urldate = {2022-11-14},
  abstract = {Mobile manipulators installed in warehouses and factories for conveying goods between working stations need to meet the requirements of time-critical workflows. Moreover, the systems are expected to deal with changing tasks, cluttered environments and constraints imposed by the goods to be delivered. In this paper, we present a novel planning framework for generating asymptotically optimal paths for mobile manipulators subject to task constraints. Our approach introduces the Bidirectional Informed RRT* (BI2RRT*) that extends the Informed RRT* [1] towards bidirectional search and satisfaction of end-effector task constraints. In various experiments, we demonstrate the efficiency of BI2RRT* for both unconstrained and constrained mobile manipulation planning problems. As the results show, our planning framework finds better solutions than Informed RRT* and Bidirectional RRT* in less planning.},
  eventtitle = {2016 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  isbn = {978-1-5090-3762-9},
  langid = {english},
  file = {/home/julin/Zotero/storage/876L2HE9/Burget et al. - 2016 - BI 2 RRT An efficient sampling-based p.pdf}
}

@inproceedings{carollComparisonInverseKinematics2020,
  title = {Comparison of {{Inverse Kinematics Algorithms}} for {{Digital Twin Industry}} 4.0 {{Applications}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Caroll, T. and Hernandez, G. and Koutitas, G. and Wierschem, D. and Mendez, F. and Vallez, D. and Aslan, S. and Koldenhoven, R. and Jimenez, J.},
  date = {2020-10},
  pages = {3319--3326},
  issn = {2577-1655},
  doi = {10.1109/SMC42975.2020.9283253},
  abstract = {This paper presents two Inverse Kinematics (IK) algorithms that are used for digital twin Augmented Reality (AR) applications. The first algorithm is a simple Inverse Kinematics (IK) Unity code that considers up to 9 points on the human body to model the motion. The second algorithm is the BIO IK that can consider up to 38 points. The performance of the algorithms is compared with data obtained by a Motion Capture (MoCap) measurement system. The metric of accuracy was used to quantify the performance evaluation and was modeled as the error of the position of the modeled joints of a human avatar with those measured by the MoCap system. It is observed that the obtained accuracy of the position increases with the number of points that is considered by the IK algorithm. For the purpose of this investigation, a MoCap system based on 13 cameras and 38 markers on the human body was used to measure the location of the joints of a human operator performing specific motions. The motion of lifting was the epicenter of the investigation that causes the larger amount of accidents in typical manufacturing facilities. The application of this research falls within the concepts of Digital Twin (DT) in Industry 4.0 scenarios.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  keywords = {Augmented Reality,Avatars,Biological system modeling,Digital twin,Digital Twin,Industries,Industry 4.0,Inverse Kinematics,Kinematics,Motion Capture Data,Production facilities,Real-time systems,Virtual Reality},
  file = {/home/julin/Zotero/storage/BDEQ2AUM/Caroll et al. - 2020 - Comparison of Inverse Kinematics Algorithms for Di.pdf;/home/julin/Zotero/storage/BGE7MYC9/9283253.html}
}

@misc{castagnaMultiAgentTransferLearning2021,
  title = {Multi-{{Agent Transfer Learning}} in {{Reinforcement Learning-Based Ride-Sharing Systems}}},
  author = {Castagna, Alberto and Dusparic, Ivana},
  date = {2021-12-01},
  number = {arXiv:2112.00424},
  eprint = {2112.00424},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2112.00424},
  urldate = {2022-11-10},
  abstract = {Reinforcement learning (RL) has been used in a range of simulated real-world tasks, e.g., sensor coordination, traffic light control, and on-demand mobility services. However, real world deployments are rare, as RL struggles with dynamic nature of real world environments, requiring time for learning a task and adapting to changes in the environment. Transfer Learning (TL) can help lower these adaptation times. In particular, there is a significant potential of applying TL in multi-agent RL systems, where multiple agents can share knowledge with each other, as well as with new agents that join the system. To obtain the most from inter-agent transfer, transfer roles (i.e., determining which agents act as sources and which as targets), as well as relevant transfer content parameters (e.g., transfer size) should be selected dynamically in each particular situation. As a first step towards fully dynamic transfers, in this paper we investigate the impact of TL transfer parameters with fixed source and target roles. Specifically, we label every agent-environment interaction with agent's epistemic confidence, and we filter the shared examples using varying threshold levels and sample sizes. We investigate impact of these parameters in two scenarios, a standard predator-prey RL benchmark and a simulation of a ride-sharing system with 200 vehicle agents and 10,000 ride-requests.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Multiagent Systems},
  file = {/home/julin/Zotero/storage/F9AXQE3S/Castagna und Dusparic - 2021 - Multi-Agent Transfer Learning in Reinforcement Lea.pdf;/home/julin/Zotero/storage/Z6X3NCTT/2112.html}
}

@article{chembulyTrajectoryPlanningRedundant2018,
  title = {Trajectory {{Planning}} of {{Redundant Manipulators Moving}} along {{Constrained Path}} and {{Avoiding Obstacles}}},
  author = {Chembuly, V. V. M. J. Satish and Voruganti, Hari Kumar},
  date = {2018-01-01},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  series = {International {{Conference}} on {{Robotics}} and {{Smart Manufacturing}} ({{RoSMa2018}})},
  volume = {133},
  pages = {627--634},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2018.07.094},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050918310469},
  urldate = {2022-11-14},
  abstract = {An optimum trajectory planning for a planar redundant manipulators is presented by minimizing the power consumption, when its end effector is commanded to move in its prescribed path. The Equations of motion of the robot manipulator are determined using Lagrange formulation. In order to accomplish a desired trajectory, the displacements of the revolute joints are interpolated as polynomial functions of time. The proposed approach generates the trajectory for the manipulator joints and end-effector by minimizing total power consumption by taking the kinematic, dynamic constraints and the obstacles in the workspace in to account. The methodology is illustrated using a planar 3-Degrees of Freedom (DOF) robot using two types of motion planning simulations; point to point motion and continuous path motion planning. Simulation results have been reported for the joint trajectories, end–effector motion for the above two cases. Results of joint trajectories are smooth and efficient.},
  langid = {english},
  keywords = {Obstacle avoidance,Redundant manipulators,Trajectory planning},
  file = {/home/julin/Zotero/storage/7TPGCP6X/Chembuly und Voruganti - 2018 - Trajectory Planning of Redundant Manipulators Movi.pdf;/home/julin/Zotero/storage/I6KCBXYA/S1877050918310469.html}
}

@article{chettibiMinimumCostTrajectory2004,
  title = {Minimum Cost Trajectory Planning for Industrial Robots},
  author = {Chettibi, T. and Lehtihet, H. E. and Haddad, M. and Hanchi, S.},
  date = {2004-07-01},
  journaltitle = {European Journal of Mechanics - A/Solids},
  shortjournal = {European Journal of Mechanics - A/Solids},
  volume = {23},
  number = {4},
  pages = {703--715},
  issn = {0997-7538},
  doi = {10.1016/j.euromechsol.2004.02.006},
  url = {https://www.sciencedirect.com/science/article/pii/S0997753804000324},
  urldate = {2022-11-14},
  abstract = {We discuss the problem of minimum cost trajectory planning for robotic manipulators. It consists of linking two points in the operational space while minimizing a cost function, taking into account dynamic equations of motion as well as bounds on joint positions, velocities, jerks and torques. This generic optimal control problem is transformed, via a clamped cubic spline model of joint temporal evolutions, into a non-linear constrained optimization problem which is treated then by the Sequential Quadratic Programming (SQP) method. Applications involving grasping mobile object or obstacle avoidance are shown to illustrate the efficiency of the proposed planner.},
  langid = {english},
  keywords = {Grasping mobile objects,Motion planning,Non-linear optimization,Obstacles avoidance,Robotic manipulators},
  file = {/home/julin/Zotero/storage/TGI5YJJS/S0997753804000324.html}
}

@article{chiaveriniReviewDampedLeastsquares1994,
  title = {Review of the Damped Least-Squares Inverse Kinematics with Experiments on an Industrial Robot Manipulator},
  author = {Chiaverini, S. and Siciliano, B. and Egeland, O.},
  date = {1994-06},
  journaltitle = {IEEE Transactions on Control Systems Technology},
  volume = {2},
  number = {2},
  pages = {123--134},
  issn = {1558-0865},
  doi = {10.1109/87.294335},
  abstract = {The goal of this paper is to present experimental results on the implementation of the damped least-squares method for the six-joint ABB IRb2000 industrial robot manipulator. A number of inverse kinematics schemes are reviewed which allow robot control through kinematic singularities. The basic scheme adopts a damped least-squares inverse of the manipulator Jacobian with a varying damping factor acting in the neighborhood of singularities. The effect of a weighted damped least-squares solution is investigated to provide user-defined accuracy capabilities along prescribed end-effector space directions. An online estimation algorithm is employed to measure closeness to singular configurations. A feedback correction error term is introduced to ensure algorithm tracking convergence and its effect on the joint velocity solution is discussed. Computational aspects are discussed in view of real-time implementation of the proposed schemes. Experimental case studies are developed to investigate manipulator performance in the case of critical end-effector trajectories passing through and near the shoulder and wrist singularities of the structure.{$<>$}},
  eventtitle = {{{IEEE Transactions}} on {{Control Systems Technology}}},
  keywords = {Damping,Error correction,Feedback,Jacobian matrices,Kinematics,Manipulators,Robot control,Service robots,Shoulder,Wrist},
  file = {/home/julin/Zotero/storage/SAPH3L4K/Chiaverini et al. - 1994 - Review of the damped least-squares inverse kinemat.pdf;/home/julin/Zotero/storage/BUZCHTMC/294335.html}
}

@online{chinenovRoboticPathPlanning2019,
  title = {Robotic {{Path Planning}}: {{RRT}} and {{RRT}}*},
  shorttitle = {Robotic {{Path Planning}}},
  author = {Chinenov, Tim},
  date = {2019-02-26T22:33:20},
  url = {https://theclassytim.medium.com/robotic-path-planning-rrt-and-rrt-212319121378},
  urldate = {2022-11-14},
  abstract = {Exploring the optimized version of a orthodox path planning algorithm},
  langid = {english},
  organization = {{Medium}},
  file = {/home/julin/Zotero/storage/UTI7TSN4/robotic-path-planning-rrt-and-rrt-212319121378.html}
}

@online{ClassesMultiagentQlearning,
  title = {Classes of {{Multiagent Q-learning Dynamics}} with Epsilon-Greedy...},
  url = {https://openreview.net/forum?id=B14d3iZdZr},
  urldate = {2022-11-08},
  abstract = {Q-learning in single-agent environments is known to converge in the limit given sufficient exploration. The same algorithm has been applied, with some success, in multi-agent environments, where...},
  langid = {english},
  organization = {{OpenReview}},
  file = {/home/julin/Zotero/storage/VRYKBEE3/forum.html}
}

@online{ConnectedPapersFind,
  title = {Connected {{Papers}} | {{Find}} and Explore Academic Papers},
  url = {https://www.connectedpapers.com/main/06c448864bb05d40877e7a11277a1b853be22dcb/A-Survey-of-Algorithms-for-Black%20Box-Safety-Validation/graph},
  urldate = {2022-10-23},
  abstract = {A unique, visual tool to help researchers and applied scientists find and explore papers relevant to their field of work.},
  langid = {english},
  file = {/home/julin/Zotero/storage/NUFVEJ5P/graph.html}
}

@online{ConnectedPapersFinda,
  title = {Connected {{Papers}} | {{Find}} and Explore Academic Papers},
  url = {https://www.connectedpapers.com/main/74b9d6896be2634a4e29ddc518038fda7f6327a6/Richard-Bellman-on-the-Birth-of-Dynamic-Programming/graph},
  urldate = {2022-11-08},
  abstract = {A unique, visual tool to help researchers and applied scientists find and explore papers relevant to their field of work.},
  langid = {english},
  file = {/home/julin/Zotero/storage/3TXKIEE2/graph.html}
}

@inproceedings{corsoAdaptiveStressTesting2019,
  title = {Adaptive {{Stress Testing}} with {{Reward Augmentation}} for {{Autonomous Vehicle Validatio}}},
  booktitle = {2019 {{IEEE Intelligent Transportation Systems Conference}} ({{ITSC}})},
  author = {Corso, Anthony and Du, Peter and Driggs-Campbell, Katherine and Kochenderfer, Mykel J.},
  date = {2019-10},
  pages = {163--168},
  doi = {10.1109/ITSC.2019.8917242},
  abstract = {Determining possible failure scenarios is a critical step in the evaluation of autonomous vehicle systems. Real world vehicle testing is commonly employed for autonomous vehicle validation, but the costs and time requirements are high. Consequently, simulation driven methods such as Adaptive Stress Testing (AST) have been proposed to aid in validation. AST formulates the problem of finding the most likely failure scenarios as a Markov decision process, which can be solved using reinforcement learning. In practice, AST tends to find scenarios where failure is unavoidable and tends to repeatedly discover the same types of failures of a system. This work addresses these issues by encoding domain relevant information into the search procedure. With this modification, the AST method discovers a larger and more expressive subset of the failure space when compared to the original AST formulation. We show that our approach is able to identify useful failure scenarios of an autonomous vehicle policy.},
  eventtitle = {2019 {{IEEE Intelligent Transportation Systems Conference}} ({{ITSC}})},
  keywords = {Acceleration,Adaptive systems,Automobiles,Autonomous vehicles,Safety,Stress,Testing},
  file = {/home/julin/Zotero/storage/GN2M4XA7/Corso et al. - 2019 - Adaptive Stress Testing with Reward Augmentation f.pdf;/home/julin/Zotero/storage/35PX6FCG/8917242.html}
}

@inproceedings{corsoAdaptiveStressTesting2019a,
  title = {Adaptive {{Stress Testing}} with {{Reward Augmentation}} for {{Autonomous Vehicle Validatio}}},
  booktitle = {2019 {{IEEE Intelligent Transportation Systems Conference}} ({{ITSC}})},
  author = {Corso, Anthony and Du, Peter and Driggs-Campbell, Katherine and Kochenderfer, Mykel J.},
  date = {2019-10},
  pages = {163--168},
  doi = {10.1109/ITSC.2019.8917242},
  abstract = {Determining possible failure scenarios is a critical step in the evaluation of autonomous vehicle systems. Real world vehicle testing is commonly employed for autonomous vehicle validation, but the costs and time requirements are high. Consequently, simulation driven methods such as Adaptive Stress Testing (AST) have been proposed to aid in validation. AST formulates the problem of finding the most likely failure scenarios as a Markov decision process, which can be solved using reinforcement learning. In practice, AST tends to find scenarios where failure is unavoidable and tends to repeatedly discover the same types of failures of a system. This work addresses these issues by encoding domain relevant information into the search procedure. With this modification, the AST method discovers a larger and more expressive subset of the failure space when compared to the original AST formulation. We show that our approach is able to identify useful failure scenarios of an autonomous vehicle policy.},
  eventtitle = {2019 {{IEEE Intelligent Transportation Systems Conference}} ({{ITSC}})},
  keywords = {Acceleration,Adaptive systems,Automobiles,Autonomous vehicles,Safety,Stress,Testing},
  file = {/home/julin/Zotero/storage/9CBNEC8N/8917242.html}
}

@article{corsoALGORITHMSBLACKBOXSAFETY,
  title = {{{ALGORITHMS FOR BLACK-BOX SAFETY VALIDATION}}},
  author = {Corso, Anthony},
  pages = {170},
  langid = {english},
  file = {/home/julin/Zotero/storage/HUXNPDRA/Corso - ALGORITHMS FOR BLACK-BOX SAFETY VALIDATION.pdf}
}

@article{corsoSurveyAlgorithmsBlackBox2020,
  title = {A {{Survey}} of {{Algorithms}} for {{Black-Box Safety Validation}} of {{Cyber-Physical Systems}}},
  author = {Corso, Anthony and Moss, Robert J. and Koren, Mark and Lee, Ritchie and Kochenderfer, Mykel J.},
  date = {2020-05-01},
  journaltitle = {arXiv e-prints},
  url = {https://ui.adsabs.harvard.edu/abs/2020arXiv200502979C},
  urldate = {2022-10-23},
  abstract = {Autonomous cyber-physical systems (CPS) can improve safety and efficiency for safety-critical applications, but require rigorous testing before deployment. The complexity of these systems often precludes the use of formal verification and real-world testing can be too dangerous during development. Therefore, simulation-based techniques have been developed that treat the system under test as a black box operating in a simulated environment. Safety validation tasks include finding disturbances in the environment that cause the system to fail (falsification), finding the most-likely failure, and estimating the probability that the system fails. Motivated by the prevalence of safety-critical artificial intelligence, this work provides a survey of state-of-the-art safety validation techniques for CPS with a focus on applied algorithms and their modifications for the safety validation problem. We present and discuss algorithms in the domains of optimization, path planning, reinforcement learning, and importance sampling. Problem decomposition techniques are presented to help scale algorithms to large state spaces, which are common for CPS. A brief overview of safety-critical applications is given, including autonomous vehicles and aircraft collision avoidance systems. Finally, we present a survey of existing academic and commercially available safety validation tools.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control,Statistics - Machine Learning},
  annotation = {ADS Bibcode: 2020arXiv200502979C},
  file = {/home/julin/Zotero/storage/IB3FVZCW/Corso et al. - 2020 - A Survey of Algorithms for Black-Box Safety Valida.pdf}
}

@online{CosiMo,
  title = {CosiMo},
  shorttitle = {CosiMo},
  url = {https://www.uni-augsburg.de/de/fakultaet/fai/isse/projects/cosimo/},
  urldate = {2020-11-02},
  langid = {ngerman},
  organization = {{Mit maschinellem Lernen zur effizienten Volumenfertigung von carbonfaserverstärkten Kunststoff-Leichtbauteilen}},
  file = {/home/julin/Zotero/storage/Y84S9JVC/cosimo.html}
}

@book{craigIntroductionRoboticsMechanics2009,
  title = {Introduction to Robotics: Mechanics and Control},
  shorttitle = {Introduction to Robotics},
  author = {Craig, John J.},
  date = {2009},
  edition = {Third edition, Indian subcontinent adaptation},
  publisher = {{Pearson}},
  location = {{Chennai}},
  isbn = {978-81-317-1836-0},
  langid = {english},
  annotation = {OCLC: 1152947479}
}

@inproceedings{dannGuaranteesEpsilonGreedyReinforcement2022,
  title = {Guarantees for {{Epsilon-Greedy Reinforcement Learning}} with {{Function Approximation}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Dann, Chris and Mansour, Yishay and Mohri, Mehryar and Sekhari, Ayush and Sridharan, Karthik},
  date = {2022-06-28},
  pages = {4666--4689},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v162/dann22a.html},
  urldate = {2022-11-08},
  abstract = {Myopic exploration policies such as epsilon-greedy, softmax, or Gaussian noise fail to explore efficiently in some reinforcement learning tasks and yet, they perform well in many others. In fact, in practice, they are often selected as the top choices, due to their simplicity. But, for what tasks do such policies succeed? Can we give theoretical guarantees for their favorable performance? These crucial questions have been scarcely investigated, despite the prominent practical importance of these policies. This paper presents a theoretical analysis of such policies and provides the first regret and sample-complexity bounds for reinforcement learning with myopic exploration. Our results apply to value-function-based algorithms in episodic MDPs with bounded Bellman Eluder dimension. We propose a new complexity measure called myopic exploration gap, denoted by alpha, that captures a structural property of the MDP, the exploration policy and the given value function class. We show that the sample-complexity of myopic exploration scales quadratically with the inverse of this quantity, 1 / alpha\^2. We further demonstrate through concrete examples that myopic exploration gap is indeed favorable in several tasks where myopic exploration succeeds, due to the corresponding dynamics and reward structure.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/home/julin/Zotero/storage/D8KMMQJ4/Dann et al. - 2022 - Guarantees for Epsilon-Greedy Reinforcement Learni.pdf}
}

@online{DCGANTutorialPyTorch,
  title = {{{DCGAN Tutorial}} — {{PyTorch Tutorials}} 1.7.0 Documentation},
  url = {https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html?highlight=gan},
  urldate = {2020-10-30}
}

@article{degierControlRoboticArm2015,
  title = {Control of a Robotic Arm: {{Application}} to on-Surface {{3D-printing}}},
  shorttitle = {Control of a Robotic Arm},
  author = {De Gier, M. R.},
  date = {2015},
  url = {https://repository.tudelft.nl/islandora/object/uuid%3Aa674a3fa-2534-44c4-b251-1e49a5194079},
  urldate = {2022-12-09},
  abstract = {3D-printing, also called Additive Manufacturing, is a rapidly developing technique in manufacturing. Nowadays 20\% of the printed products is a ?nal product, the rest is used in Rapid Prototyping. It is claimed that in 2020, 50\% of the printed output is a ?nal product. The overall goal of this research is to print 3D-structures on curved surfaces. The print technique used is called Drop-on-Demand and uses a print head with multiple nozzles. The technique enables accurate and fast 3D-prints, but needs a 6-DOF manipulator to be able to print on curved surfaces. For this purpose a 6-DOF robotic arm, the UR5, is used. In 2013 a working prototype is developed by C.J. Kruit. It was proven that a robotic arm can be bene?cial to Additive Manufacturing. Still as a ?rst prototype there is much room for improvements. The goal of this research is develop a control strategy to be able to print accurately on double curved surfaces. Model Predictive Control is used as a strategy to minimize the error of the print. In this research also an approach to acquire a local model of the UR5 is developed. Furthermore feasibility of the desired printing path and safety of using the UR5 are topics of this research.},
  langid = {english},
  file = {/home/julin/Zotero/storage/8QZLDDUA/De Gier - 2015 - Control of a robotic arm Application to on-surfac.pdf}
}

@unpublished{demirPatchBasedImageInpainting2018,
  title = {Patch-{{Based Image Inpainting}} with {{Generative Adversarial Networks}}},
  author = {Demir, Ugur and Unal, Gozde},
  date = {2018-03-20},
  eprint = {1803.07422},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Area of image inpainting over relatively large missing regions recently advanced substantially through adaptation of dedicated deep neural networks. However, current network solutions still introduce undesired artifacts and noise to the repaired regions. We present an image inpainting method that is based on the celebrated generative adversarial network (GAN) framework. The proposed PGGAN method includes a discriminator network that combines a global GAN (G-GAN) architecture with a patchGAN approach. PGGAN first shares network layers between G-GAN and patchGAN, then splits paths to produce two adversarial losses that feed the generator network in order to capture both local continuity of image texture and pervasive global features in images. The proposed framework is evaluated extensively, and the results including comparison to recent state-of-the-art demonstrate that it achieves considerable improvements on both visual and quantitative evaluations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/julin/Zotero/storage/X3UK2N7V/Demir und Unal - 2018 - Patch-Based Image Inpainting with Generative Adver.pdf;/home/julin/Zotero/storage/7TKVJXWC/1803.html}
}

@article{denavitKinematicNotationLowerPair1955,
  title = {A {{Kinematic Notation}} for {{Lower-Pair Mechanisms Based}} on {{Matrices}}},
  author = {Denavit, J. and Hartenberg, R. S.},
  date = {1955-06-01},
  journaltitle = {Journal of Applied Mechanics},
  volume = {22},
  number = {2},
  pages = {215--221},
  issn = {0021-8936, 1528-9036},
  doi = {10.1115/1.4011045},
  url = {https://asmedigitalcollection.asme.org/appliedmechanics/article/22/2/215/1110292/A-Kinematic-Notation-for-Lower-Pair-Mechanisms},
  urldate = {2022-12-02},
  abstract = {Abstract             A symbolic notation devised by Reuleaux to describe mechanisms did not recognize the necessary number of variables needed for complete description. A reconsideration of the problem leads to a symbolic notation which permits the complete description of the kinematic properties of all lower-pair mechanisms by means of equations. The symbolic notation also yields a method for studying lower-pair mechanisms by means of matrix algebra; two examples of application to space mechanisms are given.},
  langid = {english}
}

@article{eberlyDynamicCollisionDetection,
  title = {Dynamic {{Collision Detection}} Using {{Oriented Bounding Boxes}}},
  author = {Eberly, David},
  pages = {40},
  langid = {english},
  file = {/home/julin/Zotero/storage/8I8NJJC7/Eberly - Dynamic Collision Detection using Oriented Boundin.pdf}
}

@article{erdosOptimizedJointMotion2016,
  title = {Optimized Joint Motion Planning for Redundant Industrial Robots},
  author = {Erdos, Gábor and Kovacs, Andras and Váncza, J.},
  date = {2016-01-07},
  journaltitle = {CIRP Annals - Manufacturing Technology},
  shortjournal = {CIRP Annals - Manufacturing Technology},
  volume = {65},
  doi = {10.1016/j.cirp.2016.04.024},
  abstract = {The paper presents a model and solution method for optimized robot joint motion planning of redundant industrial robots that execute a set of tasks in a complex work environment, in face of various technological and geometric constraints. The approach aims at directly exploiting redundancy to optimize a given performance measure, e.g., cycle time. Alternative configurations along the path are captured in a graph model, whereas bi-directional transition between task and configuration spaces facilitates generating relevant, collision-free configurations only. Re-parametrization of the trajectory warrants compliance with the robot's kinematic constraints. Successful application of the method is demonstrated in remote laser welding.},
  file = {/home/julin/Zotero/storage/3FWLZ85J/Erdos et al. - 2016 - Optimized joint motion planning for redundant indu.pdf}
}

@article{fixDiscriminatoryAnalysisNonparametric1989,
  title = {Discriminatory {{Analysis}}. {{Nonparametric Discrimination}}: {{Consistency Properties}}},
  shorttitle = {Discriminatory {{Analysis}}. {{Nonparametric Discrimination}}},
  author = {Fix, Evelyn and Hodges, J. L.},
  date = {1989-12},
  journaltitle = {International Statistical Review / Revue Internationale de Statistique},
  shortjournal = {International Statistical Review / Revue Internationale de Statistique},
  volume = {57},
  number = {3},
  eprint = {1403797},
  eprinttype = {jstor},
  pages = {238},
  issn = {03067734},
  doi = {10.2307/1403797}
}

@misc{fujimotoAddressingFunctionApproximation2018,
  title = {Addressing {{Function Approximation Error}} in {{Actor-Critic Methods}}},
  author = {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  options = {useprefix=true},
  date = {2018-10-22},
  number = {arXiv:1802.09477},
  eprint = {1802.09477},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1802.09477},
  urldate = {2022-11-24},
  abstract = {In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/julin/Zotero/storage/CKBHBUN9/Fujimoto et al. - 2018 - Addressing Function Approximation Error in Actor-C.pdf;/home/julin/Zotero/storage/GJ7Z6TT3/1802.html}
}

@online{GitHubLornatangTfgans,
  title = {{{GitHub}} - {{Lornatang}}/Tf-Gans: {{Tensorflow}} Implements the Most Primitive {{GAN}}},
  url = {https://github.com/Lornatang/tf-gans},
  urldate = {2020-10-30}
}

@article{goldenbergCompleteGeneralizedSolution1985,
  title = {A Complete Generalized Solution to the Inverse Kinematics of Robots},
  author = {Goldenberg, A. and Benhabib, B. and Fenton, R.},
  date = {1985-03},
  journaltitle = {IEEE Journal on Robotics and Automation},
  volume = {1},
  number = {1},
  pages = {14--20},
  issn = {2374-8710},
  doi = {10.1109/JRA.1985.1086995},
  abstract = {The kinematic transformation between task space and joint configuration coordinates is nonlinear and configuration dependent. A solution to the inverse kinematics is a vector of joint configuration coordinates that corresponds to a set of task space coordinates. For a class of robots closed form solutions always exist, but constraints on joint displacements cannot be systematically incorporated in the process of obtaining a solution. An iterative solution is presented that is suitable for any class of robots having rotary or prismatic joints, with any arbitrary number of degrees of freedom, including both standard and kinematically redundant robots. The solution can be obtained subject to specified constraints and based on certain performance criteria. The solution is based on a new rapidly convergent constrained nonlinear optimization algorithm which uses a modified Newton-Raphson technique for solving a system nonlinear equations. The algorithm is illustrated using as an example a kinematically redundant robot.},
  eventtitle = {{{IEEE Journal}} on {{Robotics}} and {{Automation}}},
  keywords = {Closed-form solution,Constraint optimization,End effectors,Iterative methods,Manipulators,Nonlinear equations,Orbital robotics,Robot control,Robot kinematics,Service robots},
  file = {/home/julin/Zotero/storage/EFDA8CHH/Goldenberg et al. - 1985 - A complete generalized solution to the inverse kin.pdf;/home/julin/Zotero/storage/688SJD72/1086995.html}
}

@book{goodfellowDeepLearning2016,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {{MIT Press}},
  url = {https://www.deeplearningbook.org/},
  urldate = {2020-11-10},
  file = {/home/julin/Zotero/storage/JKF3SXA5/www.deeplearningbook.org.html}
}

@misc{goodfellowExplainingHarnessingAdversarial2015,
  title = {Explaining and {{Harnessing Adversarial Examples}}},
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  date = {2015-03-20},
  number = {arXiv:1412.6572},
  eprint = {1412.6572},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1412.6572},
  url = {http://arxiv.org/abs/1412.6572},
  urldate = {2022-10-28},
  abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/julin/Zotero/storage/U5BBH7ZP/Goodfellow et al. - 2015 - Explaining and Harnessing Adversarial Examples.pdf;/home/julin/Zotero/storage/G32C73BY/1412.html}
}

@unpublished{goodfellowGenerativeAdversarialNetworks2014,
  title = {Generative {{Adversarial Networks}}},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2014-06-10},
  eprint = {1406.2661},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/julin/Zotero/storage/FXKDWASC/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf}
}

@article{groessingEvaluationReproducibilityCapacitive2015,
  title = {An Evaluation of the Reproducibility of Capacitive Sensor Based In-Plane Permeability Measurements:{{A}} Benchmarking Study},
  shorttitle = {An Evaluation of the Reproducibility of Capacitive Sensor Based In-Plane Permeability Measurements},
  author = {Groessing, H. and Becker, D. and Kaufmann, S. and Schledjewski, R. and Mitschang, P.},
  date = {2015},
  journaltitle = {Express Polymer Letters},
  shortjournal = {Express Polym. Lett.},
  volume = {9},
  number = {2},
  pages = {129--142},
  issn = {1788618X},
  doi = {10.3144/expresspolymlett.2015.14},
  url = {http://www.expresspolymlett.com/letolt.php?file=EPL-0005624&mi=c},
  urldate = {2020-11-10},
  abstract = {A benchmark study for permeability measurement is presented. In the past studies of other research groups which focused on the reproducibility of 1D-permeability measurements showed high standard deviations of the gained permeability values (25\%), even though a defined test rig with required specifications was used. Within this study, the reproducibility of capacitive in-plane permeability testing system measurements was benchmarked by comparing results of two research sites using this technology. The reproducibility was compared by using a glass fibre woven textile and carbon fibre non crimped fabric (NCF). These two material types were taken into consideration due to the different electrical properties of glass and carbon with respect to dielectric capacitive sensors of the permeability measurement systems. In order to determine the unsaturated permeability characteristics as function of fibre volume content the measurements were executed at three different fibre volume contents including five repetitions. It was found that the stability and reproducibility of the presented in-plane permeability measurement system is very good in the case of the glass fibre woven textiles. This is true for the comparison of the repetition measurements as well as for the comparison between the two different permeameters. These positive results were confirmed by a comparison to permeability values of the same textile gained with an older generation permeameter applying the same measurement technology.},
  langid = {english},
  file = {/home/julin/Zotero/storage/WUGBBKVF/Groessing et al. - 2015 - An evaluation of the reproducibility of capacitive.pdf}
}

@article{grossingFlowFrontAdvancement2016,
  title = {Flow Front Advancement during Composite Processing: Predictions from Numerical Filling Simulation Tools in Comparison with Real-World Experiments},
  shorttitle = {Flow Front Advancement during Composite Processing},
  author = {Grössing, Harald and Stadlmajer, Natalie and Fauster, Ewald and Fleischmann, Martin and Schledjewski, Ralf},
  date = {2016},
  journaltitle = {Polymer Composites},
  volume = {37},
  number = {9},
  pages = {2782--2793},
  issn = {1548-0569},
  doi = {10.1002/pc.23474},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pc.23474},
  urldate = {2020-11-02},
  abstract = {Liquid composite molding (LCM) techniques are innovative manufacturing processes for processing fiber reinforced polymer parts used e.g. for aerospace structures. Thereby the reinforcing material is placed in a mold and infiltrated with a low viscosity polymer matrix. Increasing production rates as well as part complexity lead to high production risks such as air inclusions or incomplete mold filling. Numerical mold filling simulations are promising tools enabling the composite manufacturing engineer to detect dry spots in the mold and find the optimal positions of the resin entry and ventilation system at an early process development stage. Today, different numerical models and software packages are available for modeling the flow through the reinforcing structure for visualization of the flow behavior. The goal of this study is the systematic comparison of two different software packages, namely PAM-RTM® and OpenFOAM. Both software tools are operated as they are commonly foreseen. Real world experiments under real process conditions are the basis for the assessment of the numerical predictions. The resin transfer molding (RTM) experiments are executed in a tool with a transparent upper mold half in order to see the flow front advancement. POLYM. COMPOS., 37:2782–2793, 2016. © 2015 Society of Plastics Engineers},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pc.23474},
  file = {/home/julin/Zotero/storage/2ZW62X5R/Grössing et al. - 2016 - Flow front advancement during composite processing.pdf;/home/julin/Zotero/storage/IFK3WF6U/pc.html}
}

@online{guptaGettingStartedGANs2020,
  title = {Getting {{Started}} with {{GANs Using PyTorch}}},
  author = {Gupta, Shubham},
  date = {2020-07-01T03:38:31},
  url = {https://towardsdatascience.com/getting-started-with-gans-using-pytorch-78e7c22a14a5},
  urldate = {2020-10-30},
  abstract = {We will see the ability of GAN to generate new images which makes GANs look a little bit “magic”, at first sight.},
  langid = {english},
  organization = {{Medium}}
}

@thesis{hampusanderssonFalsificationRobotSafety2021,
  type = {mathesis},
  title = {Falsification of {{Robot Safety Systems}} Using {{Deep Reinforcement Learning}}},
  author = {{Hampus Andersson} and {Divya Kara}},
  date = {2021},
  institution = {{Chalmers University of Technology}},
  location = {{Gothenburg, Sweden}},
  url = {https://odr.chalmers.se/server/api/core/bitstreams/2f3d53e7-1a9e-432b-9565-39171ac1df4c/content},
  urldate = {2022-10-26},
  abstract = {Robot stations today have large safety zones around each station where humans are not allowed to be while the robots are moving. Often these zones are fenced, but they can also be monitored to stop the motions if anyone enters. However, it is common that the total area of a new robot station area must be kept small, or maybe an operator must be able to interact with the station, hence requiring smaller safety zones. In order to reduce these safety zones, integrators need to guarantee that the robot stations design are safe for any type of human behavior by doing a risk assessment and safety evaluation. This will support this risk assessment and safety validation of robot safety zones by developing a function that tries to falsify a station using AI and Deep Reinforcement Learning (DRL) to find defects as unexpected hitting_itself in the environment.},
  langid = {english},
  pagetotal = {113},
  file = {/home/julin/Zotero/storage/9Q7RL9Z2/content.pdf}
}

@inproceedings{hanConfigurationSpaceDecomposition2020,
  title = {Configuration {{Space Decomposition}} for {{Learning-based Collision Checking}} in {{High-DOF Robots}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Han, Yiheng and Zhao, Wang and Pan, Jia and Liu, Yong-Jin},
  date = {2020-10-24},
  pages = {5678--5684},
  publisher = {{IEEE}},
  location = {{Las Vegas, NV, USA}},
  doi = {10.1109/IROS45743.2020.9341526},
  url = {https://ieeexplore.ieee.org/document/9341526/},
  urldate = {2022-12-09},
  abstract = {Motion planning for robots of high degrees-offreedom (DOFs) is an important problem in robotics with sampling-based methods in configuration space C as one popular solution. Recently, machine learning methods have been introduced into sampling-based motion planning methods, which train a classifier to distinguish collision free subspace from in-collision subspace in C. In this paper, we propose a novel configuration space decomposition method and show two nice properties resulted from this decomposition. Using these two properties, we build a composite classifier that works compatibly with previous machine learning methods by using them as the elementary classifiers. Experimental results are presented, showing that our composite classifier outperforms state-of-the-art single-classifier methods by a large margin. A real application of motion planning in a multi-robot system in plant phenotyping using three UR5 robotic arms is also presented.},
  eventtitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  isbn = {978-1-72816-212-6},
  langid = {english},
  file = {/home/julin/Zotero/storage/J52P9PRY/Han et al. - 2020 - Configuration Space Decomposition for Learning-bas.pdf}
}

@inproceedings{hasseltDoubleQlearning2010,
  title = {Double {{Q-learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Hasselt, Hado},
  date = {2010},
  volume = {23},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2010/hash/091d584fced301b442654dd8c23b3fc9-Abstract.html},
  urldate = {2022-11-24},
  abstract = {In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly. This poor performance is caused by large overestimations of action values. These overestimations result from a positive bias that is introduced because Q-learning uses the maximum action value as an approximation for the maximum expected action value. We introduce an alternative way to approximate the maximum expected value for any set of random variables. The obtained double estimator method is shown to sometimes underestimate rather than overestimate the maximum expected value. We apply the double estimator to Q-learning to construct Double Q-learning, a new off-policy reinforcement learning algorithm. We show the new algorithm converges to the optimal policy and that it performs well in some settings in which Q-learning performs poorly due to its overestimation.},
  file = {/home/julin/Zotero/storage/DIWNKWWF/Hasselt - 2010 - Double Q-learning.pdf}
}

@report{hawkinsAnalyticInverseKinematics2013,
  type = {Technical Report},
  title = {Analytic {{Inverse Kinematics}} for the {{Universal Robots UR-5}}/{{UR-10 Arms}}},
  author = {Hawkins, Kelsey P.},
  date = {2013-12-07},
  institution = {{Georgia Institute of Technology}},
  url = {https://smartech.gatech.edu/handle/1853/50782},
  urldate = {2022-11-25},
  langid = {american},
  annotation = {Accepted: 2014-02-03T16:31:04Z},
  file = {/home/julin/Zotero/storage/6C7VEXZY/Hawkins - 2013 - Analytic Inverse Kinematics for the Universal Robo.pdf;/home/julin/Zotero/storage/5WYV5749/50782.html}
}

@report{heywoodRoad2050Potential2015,
  title = {On the {{Road}} toward 2050: {{Potential}} for {{Substantial Reductions}} in {{Light-Duty Vehicle Energy Use}} and {{Greenhouse Gas Emissions}}},
  author = {Heywood, John and MacKenzie, Mac},
  year = {Nov-2015},
  pages = {300},
  institution = {{Massachusetts Institute of Technology}},
  abstract = {This report summarizes the results of an ongoing research program that assesses the extent to which improvements and changes in powertrain and vehicle technologies, and fuels changes, could reduce the fuel consumption and greenhouse gas (GHG) emissions of light-duty road vehicles. This research was done by a team of graduate students from 2009 to 2014, and includes some 20 projects. It continues our group’s efforts to provide a more complete summary of the various options available, and an increasingly detailed knowledge base with which to assess these options, as we move forward. It follows on from three earlier reports: On the Road in 2020 published in 2000 and On the Road in 2035 published in 2008, and a strategy and policy-based report, An Action Plan for Cars, published at the end of 2009.},
  langid = {american},
  file = {/home/julin/Zotero/storage/Q6DQQ2ZT/MITEI-RP-2015-001.pdf}
}

@thesis{hjelmelandValidationMarineCollision2022,
  type = {mathesis},
  title = {Validation of Marine Collision Avoidance Systems Using {{Adaptive Stress Testing}}},
  author = {Hjelmeland, Hanna Waage},
  date = {2022},
  institution = {{NTNU}},
  url = {https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/3013359},
  urldate = {2022-11-05},
  abstract = {Maritime Autonome Overflate-Skip (MAOS) har potensiale til å bidra til en mer fleksibel urban mobilitetsløsning med reduserte utslipp av drivhusgasser. For å muliggjøre maritim autonomi må systemene gjennomgå grundig sikkerhetsvalidering. Fordi autonome systemer består av flere lag med komplekse systemer som utfører vurdering og beslutningstaking, er ikke tradisjonelle metoder for sikkerhetsvalidering tilstrekkelig for å teste systemene. For å adressere dette problemet har nylig forskning etterlyst nye metoder for å utføre intelligent simuleringsbasert sikkerhetsvalidering av MAOS. Det er foreslått flere metoder for å automatisk identifisere scenarier som er utfordrende for MAOS å navigere i, for å redusere antall nødvendige testscenarier og utføre tilstrekkelig fullstendig testing. Forfatteren har imidlertid ikke funnet noen metoder for bruk i maritim autonomi, som tar for seg måten simuleringen av scenariet utvikler seg. Slike metoder har blitt brukt på autonome kjøretøy og flysystemer ved bruk av metoder som f.eks Adaptive Stress Testing AST. AST er en simuleringsbasert metode som bruker forsterkende læring til å utføre søk etter feil i simuleringer av systemet som testes. Feil blir funnet ved å injisere en sekvens av forstyrrelser og gradvis lære den mest effektive og sannsynlige måten å forstyrre systemet til å svikte. Dette arbeidet foreslår bruk av AST som et trinn i sikkerhetsvalideringsprosessen til MAOS. For å demonstrere metoden brukes AST i tester av to forskjellige kollisjonsunngåelses-strategier i simuleringer av den autonome passassjerfergen milliAmpere. AST utgjør en svært fleksibel metode, da den kan justeres og tilpasses domenet og det spesifikke formålet. Oppgaven foreslår flere slike tilpasninger for å forbedre metoderelevansen for det maritime domenet. Resultatene viser potensialet til AST i sikkerhetsvalideringsprosessen til MAOS, ved at mange interessante feil blir identifisert, hvilke avdekker potensielle aspekter ved de forskjellige kollisjonsunngåelse-systemene hvor det er forbedringspotensiale. Videre forskning bør utføres for å forbedre metoden og for å kombinere AST med scenario-genereringsmetoder.},
  langid = {english},
  annotation = {Accepted: 2022-08-24T17:19:52Z},
  file = {/home/julin/Zotero/storage/P8ZBEF78/Hjelmeland - 2022 - Validation of marine collision avoidance systems u.pdf;/home/julin/Zotero/storage/CW3652BH/3013359.html}
}

@online{hulsmannFormalFalsificationCriteria2022,
  type = {Masterarbeit},
  title = {Formal {{Falsification Criteria}} as a {{Basis}} for {{Behavior Planning}} Based on {{Reinforcement Learning Algorithms}}},
  author = {Hülsmann, Robert Alexander},
  date = {2022},
  publisher = {{Technische Universität Darmstadt}},
  location = {{Darmstadt}},
  doi = {10.26083/tuprints-00019116},
  url = {https://tuprints.ulb.tu-darmstadt.de/19116/},
  urldate = {2022-10-26},
  abstract = {For the purpose of compliance with behavioral rules by Autonomous Vehicle (AV), especially in urban traffic, the Behavior-Semantic Scenery Description (BSSD) can be used to describe the limits of the legal behavioral space for each route segment of a road map. In order to test the applicability of BSSD to an online behavior planner, the task of this thesis was to convert selected route segments into the BSSD format, derive behavioral boundaries as formal falsification criteria from the specification of BSSD, and subsequently use them for the application of a Reinforcement Learning (RL) behavior planner.  For this purpose, these criteria were first extracted from the specification, their logical form were identified and formalized. A training environment for the behavior planner including the simulation of other Traffic Participant (TP) and a visualization was created and the falsification criteria and the behavior planner were implemented to the extent as it was possible within the scope of this thesis. Finally, the behavior planner was trained and evaluated.  The formalization and implementation of the falsification criteria highlighted strengths and weaknesses in the machine interpretability of BSSD. Two of the six extracted criteria could not be fully formalized and implemented. For the remaining criteria, however, it was possible to complete this task.  The evaluation of the learned behavior model showed that in the training environment, a vehicle controlled by the simple behavior planner reacts to changes in the maximum permitted speeds and adjusts its speed promptly. Also, lane changes are avoided since they are prohibited or not possible in most places in the selected road section. For compliance with other falsification criteria, improvements must be made to the behavior planner and to the level of penalties for violating the behavior limits respectively rewards for error-free progress. Some suggestions for this have been given in this elaboration.},
  langid = {english},
  file = {/home/julin/Zotero/storage/DYBBR84Z/Hülsmann - 2022 - Formal Falsification Criteria as a Basis for Behav.pdf;/home/julin/Zotero/storage/IQ7R35Z7/19116.html}
}

@unpublished{isolaImagetoImageTranslationConditional2018,
  title = {Image-to-{{Image Translation}} with {{Conditional Adversarial Networks}}},
  author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
  date = {2018-11-26},
  eprint = {1611.07004},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/julin/Zotero/storage/CXYZ2VX3/Isola et al. - 2018 - Image-to-Image Translation with Conditional Advers.pdf;/home/julin/Zotero/storage/KNHTGUDQ/1611.html}
}

@software{IsseaugsburgRtmpredictions2020,
  title = {Isse-Augsburg/Rtm-Predictions},
  date = {2020-05-11T10:16:45Z},
  url = {https://github.com/isse-augsburg/rtm-predictions},
  urldate = {2020-11-02},
  abstract = {Code for the FlowFrontNet Paper; submitted to ECML 2020},
  organization = {{Institute for Software \& Systems Engineering}}
}

@online{jahobrCoordinateSystemsDenavitHartenberg2007,
  title = {Coordinate systems and Denavit-Hartenberg parameters},
  shorttitle = {Datei},
  author = {{Jahobr}},
  date = {2007},
  url = {https://commons.wikimedia.org/wiki/File:Denavit-Hartenberg-Transformation.svg},
  urldate = {2022-11-24},
  langid = {ngerman},
  file = {/home/julin/Zotero/storage/L5WI35VW/DateiDenavit-Hartenberg-Transformation.html}
}

@misc{julianValidationImageBasedNeural2020,
  title = {Validation of {{Image-Based Neural Network Controllers}} through {{Adaptive Stress Testing}}},
  author = {Julian, Kyle D. and Lee, Ritchie and Kochenderfer, Mykel J.},
  date = {2020-03-04},
  number = {arXiv:2003.02381},
  eprint = {2003.02381},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2003.02381},
  url = {http://arxiv.org/abs/2003.02381},
  urldate = {2022-10-28},
  abstract = {Neural networks have become state-of-the-art for computer vision problems because of their ability to efficiently model complex functions from large amounts of data. While neural networks can be shown to perform well empirically for a variety of tasks, their performance is difficult to guarantee. Neural network verification tools have been developed that can certify robustness with respect to a given input image; however, for neural network systems used in closed-loop controllers, robustness with respect to individual images does not address multi-step properties of the neural network controller and its environment. Furthermore, neural network systems interacting in the physical world and using natural images are operating in a black-box environment, making formal verification intractable. This work combines the adaptive stress testing (AST) framework with neural network verification tools to search for the most likely sequence of image disturbances that cause the neural network controlled system to reach a failure. An autonomous aircraft taxi application is presented, and results show that the AST method finds failures with more likely image disturbances than baseline methods. Further analysis of AST results revealed an explainable cause of the failure, giving insight into the problematic scenarios that should be addressed.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control},
  file = {/home/julin/Zotero/storage/MIBZCXDI/Julian et al. - 2020 - Validation of Image-Based Neural Network Controlle.pdf;/home/julin/Zotero/storage/XXHJLJAR/2003.html}
}

@article{kaelblingReinforcementLearningSurvey1996,
  title = {Reinforcement {{Learning}}: {{A Survey}}},
  shorttitle = {Reinforcement {{Learning}}},
  author = {Kaelbling, L. P. and Littman, M. L. and Moore, A. W.},
  date = {1996-05-01},
  journaltitle = {Journal of Artificial Intelligence Research},
  volume = {4},
  pages = {237--285},
  issn = {1076-9757},
  doi = {10.1613/jair.301},
  url = {https://www.jair.org/index.php/jair/article/view/10166},
  urldate = {2022-10-24},
  abstract = {This paper surveys the field of reinforcement learning from    a computer-science perspective. It is written to be accessible to    researchers familiar with machine learning.  Both the historical basis    of the field and a broad selection of current work are summarized.    Reinforcement learning is the problem faced by an agent that learns    behavior through trial-and-error interactions with a dynamic    environment.  The work described here has a resemblance to work in    psychology, but differs considerably in the details and in the use of    the word ``reinforcement.''  The paper discusses central issues of    reinforcement learning, including trading off exploration and    exploitation, establishing the foundations of the field via Markov    decision theory, learning from delayed reinforcement, constructing    empirical models to accelerate learning, making use of generalization    and hierarchy, and coping with hidden state.  It concludes with a    survey of some implemented systems and an assessment of the practical    utility of current methods for reinforcement learning.},
  langid = {english},
  file = {/home/julin/Zotero/storage/7ZC7RBIU/Kaelbling et al. - 1996 - Reinforcement Learning A Survey.pdf}
}

@inproceedings{karnouskosCyberPhysicalSystemsSmartGrid2011,
  title = {Cyber-{{Physical Systems}} in the {{SmartGrid}}},
  author = {Karnouskos, Stamatis},
  date = {2011-08-29},
  pages = {20--23},
  doi = {10.1109/INDIN.2011.6034829},
  abstract = {Radical changes are expected to occur in the next years in the electricity domain and the grid itself which has been almost unchanged the last 100 years. Value is created when interactions exist and this is the main thrust of the emerging SmartGrid which will heavily rely on IT technologies at several layers for monitoring and control. The basic building blocks are the existing efforts in the domain of the Internet of Things and Internet of Services, that come together with cooperation as the key enabler. The SmartGrid is a complex ecosystem of heterogeneous (cooperating) entities that interact in order to provide the envisioned functionality. Advanced business services will take advantage of the near real-time information flows among all participants. In order to realize the SmartGrid promise we will have to heavily depend on Cyber-Physical Systems (CPS) that will be able to monitor, share and manage information and actions on the business as well as the real world. CPS is seen as an integral part of the SmartGrid, hence several open issues will need to be effectively addressed.},
  eventtitle = {{{IEEE International Conference}} on {{Industrial Informatics}} ({{INDIN}})},
  file = {/home/julin/Zotero/storage/UK4KICF8/Karnouskos - 2011 - Cyber-Physical Systems in the SmartGrid.pdf}
}

@misc{karunakaranCriticalConcreteScenario2022,
  title = {Critical Concrete Scenario Generation Using Scenario-Based Falsification},
  author = {Karunakaran, Dhanoop and Berrio, Julie Stephany and Worrall, Stewart and Nebot, Eduardo},
  date = {2022-08-28},
  number = {arXiv:2208.13329},
  eprint = {2208.13329},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2208.13329},
  url = {http://arxiv.org/abs/2208.13329},
  urldate = {2022-10-26},
  abstract = {Autonomous vehicles have the potential to lower the accident rate when compared to human driving. Moreover, it is the driving force of the automated vehicles' rapid development over the last few years. In the higher Society of Automotive Engineers (SAE) automation level, the vehicle's and passengers' safety responsibility is transferred from the driver to the automated system, so thoroughly validating such a system is essential. Recently, academia and industry have embraced scenario-based evaluation as the complementary approach to road testing, reducing the overall testing effort required. It is essential to determine the system's flaws before deploying it on public roads as there is no safety driver to guarantee the reliability of such a system. This paper proposes a Reinforcement Learning (RL) based scenario-based falsification method to search for a high-risk scenario in a pedestrian crossing traffic situation. We define a scenario as risky when a system under testing (SUT) does not satisfy the requirement. The reward function for our RL approach is based on Intel's Responsibility Sensitive Safety(RSS), Euclidean distance, and distance to a potential collision.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics,I.2},
  file = {/home/julin/Zotero/storage/NYUBWBBJ/Karunakaran et al. - 2022 - Critical concrete scenario generation using scenar.pdf;/home/julin/Zotero/storage/ZSC4SVNR/2208.html}
}

@online{keimchristianRTM,
  title = {{{RTM}}},
  author = {Keim, Christian},
  url = {https://keim-fasertechnik.de/produktionsverfahren/rtm/},
  urldate = {2020-11-02},
  organization = {{Keim Kunststofftechnik GmBH}},
  file = {/home/julin/Zotero/storage/6LTWZ3A6/rtm.html}
}

@software{khazaieVrkh1996Tinypix2pix2020,
  title = {Vrkh1996/Tiny-Pix2pix},
  author = {Khazaie, Vahid Reza},
  date = {2020-08-12T07:42:00Z},
  origdate = {2019-08-26T20:27:30Z},
  url = {https://github.com/vrkh1996/tiny-pix2pix},
  urldate = {2020-11-19},
  abstract = {Redesigning the Pix2Pix model for small datasets with fewer parameters and different PatchGAN architecture},
  keywords = {gan,generative-adversarial-network,patchgan,pix2pix,pix2pix-model,tinypix2pix,unet}
}

@inproceedings{kondaActorCriticAlgorithms1999,
  title = {Actor-{{Critic Algorithms}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Konda, Vijay and Tsitsiklis, John},
  date = {1999},
  volume = {12},
  publisher = {{MIT Press}},
  url = {https://proceedings.neurips.cc/paper/1999/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html},
  urldate = {2022-12-03},
  abstract = {We  propose  and  analyze  a  class  of  actor-critic  algorithms  for  simulation-based  optimization  of  a  Markov  decision  process  over  a  parameterized  family  of randomized  stationary  policies.  These  are two-time-scale  algorithms in  which  the critic uses TD learning  with  a  linear approximation architecture and the actor is  updated  in  an  approximate  gradient  direction  based  on  information  pro(cid:173) vided by the critic.  We  show that the features for  the critic should  span a subspace prescribed by the choice of parameterization of the  actor.  We  conclude by discussing convergence properties and some  open problems.},
  file = {/home/julin/Zotero/storage/4AKXKH94/Konda und Tsitsiklis - 1999 - Actor-Critic Algorithms.pdf}
}

@inproceedings{korenAdaptiveStressTesting2018,
  title = {Adaptive {{Stress Testing}} for {{Autonomous Vehicles}}},
  booktitle = {2018 {{IEEE Intelligent Vehicles Symposium}} ({{IV}})},
  author = {Koren, Mark and Alsaif, Saud and Lee, Ritchie and Kochenderfer, Mykel J.},
  date = {2018-06},
  pages = {1--7},
  issn = {1931-0587},
  doi = {10.1109/IVS.2018.8500400},
  abstract = {This paper presents a method for testing the decision making systems of autonomous vehicles. Our approach involves perturbing stochastic elements in the vehicle's environment until the vehicle is involved in a collision. Instead of applying direct Monte Carlo sampling to find collision scenarios, we formulate the problem as a Markov decision process and use reinforcement learning algorithms to find the most likely failure scenarios. This paper presents Monte Carlo Tree Search (MCTS) and Deep Reinforcement Learning (DRL) solutions that can scale to large environments. We show that DRL can find more likely failure scenarios than MCTS with fewer calls to the simulator. A simulation scenario involving a vehicle approaching a crosswalk is used to validate the framework. Our proposed approach is very general and can be easily applied to other scenarios given the appropriate models of the vehicle and the environment.},
  eventtitle = {2018 {{IEEE Intelligent Vehicles Symposium}} ({{IV}})},
  keywords = {Autonomous vehicles,Markov processes,Monte Carlo methods,Roads,Sensors,Stress,Testing},
  file = {/home/julin/Zotero/storage/UKJB8DNW/Koren et al. - 2018 - Adaptive Stress Testing for Autonomous Vehicles.pdf;/home/julin/Zotero/storage/BMYI6AMT/8500400.html}
}

@inproceedings{korenAdaptiveStressTesting2018a,
  title = {Adaptive {{Stress Testing}} for {{Autonomous Vehicles}}},
  booktitle = {2018 {{IEEE Intelligent Vehicles Symposium}} ({{IV}})},
  author = {Koren, Mark and Alsaif, Saud and Lee, Ritchie and Kochenderfer, Mykel J.},
  date = {2018-06},
  pages = {1--7},
  issn = {1931-0587},
  doi = {10.1109/IVS.2018.8500400},
  abstract = {This paper presents a method for testing the decision making systems of autonomous vehicles. Our approach involves perturbing stochastic elements in the vehicle's environment until the vehicle is involved in a collision. Instead of applying direct Monte Carlo sampling to find collision scenarios, we formulate the problem as a Markov decision process and use reinforcement learning algorithms to find the most likely failure scenarios. This paper presents Monte Carlo Tree Search (MCTS) and Deep Reinforcement Learning (DRL) solutions that can scale to large environments. We show that DRL can find more likely failure scenarios than MCTS with fewer calls to the simulator. A simulation scenario involving a vehicle approaching a crosswalk is used to validate the framework. Our proposed approach is very general and can be easily applied to other scenarios given the appropriate models of the vehicle and the environment.},
  eventtitle = {2018 {{IEEE Intelligent Vehicles Symposium}} ({{IV}})},
  keywords = {Autonomous vehicles,Markov processes,Monte Carlo methods,Roads,Sensors,Stress,Testing},
  file = {/home/julin/Zotero/storage/8IAZ45S2/8500400.html}
}

@misc{korenEfficientAutonomyValidation2019,
  title = {Efficient {{Autonomy Validation}} in {{Simulation}} with {{Adaptive Stress Testing}}},
  author = {Koren, Mark and Kochenderfer, Mykel},
  date = {2019-07-15},
  number = {arXiv:1907.06795},
  eprint = {1907.06795},
  eprinttype = {arxiv},
  primaryclass = {cs, eess, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1907.06795},
  url = {http://arxiv.org/abs/1907.06795},
  urldate = {2022-10-28},
  abstract = {During the development of autonomous systems such as driverless cars, it is important to characterize the scenarios that are most likely to result in failure. Adaptive Stress Testing (AST) provides a way to search for the most-likely failure scenario as a Markov decision process (MDP). Our previous work used a deep reinforcement learning (DRL) solver to identify likely failure scenarios. However, the solver's use of a feed-forward neural network with a discretized space of possible initial conditions poses two major problems. First, the system is not treated as a black box, in that it requires analyzing the internal state of the system, which leads to considerable implementation complexities. Second, in order to simulate realistic settings, a new instance of the solver needs to be run for each initial condition. Running a new solver for each initial condition not only significantly increases the computational complexity, but also disregards the underlying relationship between similar initial conditions. We provide a solution to both problems by employing a recurrent neural network that takes a set of initial conditions from a continuous space as input. This approach enables robust and efficient detection of failures because the solution generalizes across the entire space of initial conditions. By simulating an instance where an autonomous car drives while a pedestrian is crossing a road, we demonstrate the solver is now capable of finding solutions for problems that would have previously been intractable.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics,Computer Science - Software Engineering,Electrical Engineering and Systems Science - Systems and Control,Statistics - Machine Learning},
  file = {/home/julin/Zotero/storage/53QMEE7B/Koren und Kochenderfer - 2019 - Efficient Autonomy Validation in Simulation with A.pdf;/home/julin/Zotero/storage/AGQJFT9G/1907.html}
}

@incollection{kucukRobotKinematicsForward2006,
  title = {Robot {{Kinematics}}: {{Forward}} and {{Inverse Kinematics}}},
  shorttitle = {Robot {{Kinematics}}},
  author = {Kucuk, Serdar and Bingul, Z.},
  date = {2006-12-01},
  doi = {10.5772/5015},
  abstract = {1},
  isbn = {978-3-86611-285-8},
  file = {/home/julin/Zotero/storage/526YZ5RQ/Kucuk und Bingul - 2006 - Robot Kinematics Forward and Inverse Kinematics.pdf}
}

@inproceedings{kunchevPathPlanningObstacle2006,
  title = {Path {{Planning}} and {{Obstacle Avoidance}} for {{Autonomous Mobile Robots}}: {{A Review}}},
  shorttitle = {Path {{Planning}} and {{Obstacle Avoidance}} for {{Autonomous Mobile Robots}}},
  booktitle = {Knowledge-{{Based Intelligent Information}} and {{Engineering Systems}}},
  author = {Kunchev, Voemir and Jain, Lakhmi and Ivancevic, Vladimir and Finn, Anthony},
  editor = {Gabrys, Bogdan and Howlett, Robert J. and Jain, Lakhmi C.},
  date = {2006},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {537--544},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11893004_70},
  abstract = {Recent advances in the area of mobile robotics caused growing attention of the armed forces, where the necessity for unmanned vehicles being able to carry out the “dull and dirty” operations, thus avoid endangering the life of the military personnel. UAV offers a great advantage in supplying reconnaissance data to the military personnel on the ground, thus lessening the life risk of the troops. In this paper we analyze various techniques for path planning and obstacle avoidance and cooperation issues for multiple mobile robots. We also present a generic dynamics and control model for steering a UAV along a collision free path from a start to a goal position.},
  isbn = {978-3-540-46539-3},
  langid = {english},
  keywords = {Goal Position,Mobile Robot,Obstacle Avoidance,Path Planning,Voronoi Diagram},
  file = {/home/julin/Zotero/storage/EHC4MIZH/Kunchev et al. - 2006 - Path Planning and Obstacle Avoidance for Autonomou.pdf}
}

@article{larsenAutoencodingPixelsUsing,
  title = {Autoencoding beyond Pixels Using a Learned Similarity Metric},
  author = {Larsen, Anders Boesen Lindbo and Sønderby, Søren Kaae and Larochelle, Hugo and Winther, Ole},
  pages = {9},
  abstract = {We present an autoencoder that leverages learned representations to better measure similarities in data space. By combining a variational autoencoder (VAE) with a generative adversarial network (GAN) we can use learned feature representations in the GAN discriminator as basis for the VAE reconstruction objective. Thereby, we replace element-wise errors with feature-wise errors to better capture the data distribution while offering invariance towards e.g. translation. We apply our method to images of faces and show that it outperforms VAEs with element-wise similarity measures in terms of visual fidelity. Moreover, we show that the method learns an embedding in which high-level abstract visual features (e.g. wearing glasses) can be modified using simple arithmetic.},
  langid = {english},
  file = {/home/julin/Zotero/storage/8C4A7SVC/Larsen et al. - Autoencoding beyond pixels using a learned similar.pdf}
}

@inproceedings{ledigPhotoRealisticSingleImage2017,
  title = {Photo-{{Realistic Single Image Super-Resolution Using}} a {{Generative Adversarial Network}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Ledig, Christian and Theis, Lucas and Huszar, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  date = {2017-07},
  pages = {105--114},
  publisher = {{IEEE}},
  location = {{Honolulu, HI}},
  doi = {10.1109/CVPR.2017.19},
  abstract = {Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image superresolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4× upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  langid = {english},
  file = {/home/julin/Zotero/storage/V2VC6FZK/Ledig et al. - 2017 - Photo-Realistic Single Image Super-Resolution Usin.pdf}
}

@inproceedings{leeAdaptiveStressTesting2015,
  title = {Adaptive Stress Testing of Airborne Collision Avoidance Systems},
  booktitle = {2015 {{IEEE}}/{{AIAA}} 34th {{Digital Avionics Systems Conference}} ({{DASC}})},
  author = {Lee, Ritchie and Kochenderfer, Mykel J. and Mengshoel, Ole J. and Brat, Guillaume P. and Owen, Michael P.},
  date = {2015-09},
  pages = {6C2-1-6C2-13},
  issn = {2155-7209},
  doi = {10.1109/DASC.2015.7311450},
  abstract = {This paper presents a scalable method to efficiently search for the most likely state trajectory leading to an event given only a simulator of a system. Our approach uses a reinforcement learning formulation and solves it using Monte Carlo Tree Search (MCTS). The approach places very few requirements on the underlying system, requiring only that the simulator provide some basic controls, the ability to evaluate certain conditions, and a mechanism to control the stochasticity in the system. Access to the system state is not required, allowing the method to support systems with hidden state. The method is applied to stress test a prototype aircraft collision avoidance system to identify trajectories that are likely to lead to near mid-air hitting_itself. We present results for both single and multi-threat encounters and discuss their relevance. Compared with direct Monte Carlo search, this MCTS method performs significantly better both in finding events and in maximizing their likelihood.},
  eventtitle = {2015 {{IEEE}}/{{AIAA}} 34th {{Digital Avionics Systems Conference}} ({{DASC}})},
  keywords = {Atmospheric modeling,Lead,Quality of service},
  file = {/home/julin/Zotero/storage/ATIZ836K/Lee et al. - 2015 - Adaptive stress testing of airborne collision avoi.pdf;/home/julin/Zotero/storage/PNVZY6PB/7311450.html}
}

@inproceedings{limReinforcementLearningRobust2013,
  title = {Reinforcement {{Learning}} in {{Robust Markov Decision Processes}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lim, Shiau Hong and Xu, Huan and Mannor, Shie},
  date = {2013},
  volume = {26},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2013/hash/0deb1c54814305ca9ad266f53bc82511-Abstract.html},
  urldate = {2022-11-08},
  abstract = {An important challenge in Markov decision processes is to ensure robustness with respect to unexpected or adversarial system behavior while taking advantage of well-behaving parts of the system. We consider a problem setting where some unknown parts of the state space can have arbitrary transitions while other parts are purely stochastic. We devise an algorithm that is adaptive to potentially adversarial behavior and show that it achieves similar regret bounds as the purely stochastic case.},
  file = {/home/julin/Zotero/storage/NISFP5XN/Lim et al. - 2013 - Reinforcement Learning in Robust Markov Decision P.pdf}
}

@misc{liPolyakRuppertAveragedQLearningStatistically2022,
  title = {Polyak-{{Ruppert-Averaged Q-Learning}} Is {{Statistically Efficient}}},
  author = {Li, Xiang and Yang, Wenhao and Liang, Jiadong and Zhang, Zhihua and Jordan, Michael I.},
  date = {2022-02-07},
  number = {arXiv:2112.14582},
  eprint = {2112.14582},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2112.14582},
  url = {http://arxiv.org/abs/2112.14582},
  urldate = {2022-11-24},
  abstract = {We study synchronous Q-learning with Polyak-Ruppert averaging (a.k.a., averaged Q-learning) in a \$\textbackslash gamma\$-discounted MDP. We establish a functional central limit theorem (FCLT) for the averaged iteration \$\textbackslash bar\{\textbackslash boldsymbol\{Q\}\}\_T\$ and show its standardized partial-sum process converges weakly to a rescaled Brownian motion. Furthermore, we show that \$\textbackslash bar\{\textbackslash boldsymbol\{Q\}\}\_T\$ is actually a regular asymptotically linear (RAL) estimator for the optimal Q-value function \$\textbackslash boldsymbol\{Q\}\^*\$ with the most efficient influence function. This implies the averaged Q-learning iteration has the smallest asymptotic variance among all RAL estimators. In addition, we present a nonasymptotic analysis for the \$\textbackslash ell\_\{\textbackslash infty\}\$ error \$\textbackslash mathbb\{E\}\textbackslash |\textbackslash bar\{\textbackslash boldsymbol\{Q\}\}\_T-\textbackslash boldsymbol\{Q\}\^*\textbackslash |\_\{\textbackslash infty\}\$, showing that for polynomial step sizes it matches the instance-dependent lower bound as well as the optimal minimax complexity lower bound. In short, our theoretical analysis shows that averaged Q-learning is statistically efficient.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/julin/Zotero/storage/B39FIPVZ/Li et al. - 2022 - Polyak-Ruppert-Averaged Q-Learning is Statisticall.pdf;/home/julin/Zotero/storage/H7UCD9JB/2112.html}
}

@inproceedings{liPrecomputedRealTimeTexture2016,
  title = {Precomputed {{Real-Time Texture Synthesis}} with {{Markovian Generative Adversarial Networks}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2016},
  author = {Li, Chuan and Wand, Michael},
  editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  date = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {702--716},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-46487-9_43},
  abstract = {This paper proposes Markovian Generative Adversarial Networks (MGANs), a method for training generative networks for efficient texture synthesis. While deep neural network approaches have recently demonstrated remarkable results in terms of synthesis quality, they still come at considerable computational costs (minutes of run-time for low-res images). Our paper addresses this efficiency issue. Instead of a numerical deconvolution in previous work, we precompute a feed-forward, strided convolutional network that captures the feature statistics of Markovian patches and is able to directly generate outputs of arbitrary dimensions. Such network can directly decode brown noise to realistic texture, or photos to artistic paintings. With adversarial training, we obtain quality comparable to recent neural texture synthesis methods. As no optimization is required at generation time, our run-time performance (0.25 M pixel images at 25 Hz) surpasses previous neural texture synthesizers by a significant margin (at least 500 times faster). We apply this idea to texture synthesis, style transfer, and video stylization.},
  isbn = {978-3-319-46487-9},
  langid = {english},
  keywords = {Adversarial generative networks,Texture synthesis},
  file = {/home/julin/Zotero/storage/YYMKS8RH/Li und Wand - 2016 - Precomputed Real-Time Texture Synthesis with Marko.pdf}
}

@article{luCollisionfreeSmoothJoint2021,
  title = {Collision-Free and Smooth Joint Motion Planning for Six-Axis Industrial Robots by Redundancy Optimization},
  author = {Lu, Yao-An and Tang, Kai and Wang, Cheng-Yong},
  date = {2021-04-01},
  journaltitle = {Robotics and Computer-Integrated Manufacturing},
  shortjournal = {Robotics and Computer-Integrated Manufacturing},
  volume = {68},
  pages = {102091},
  issn = {0736-5845},
  doi = {10.1016/j.rcim.2020.102091},
  url = {https://www.sciencedirect.com/science/article/pii/S073658452030301X},
  urldate = {2022-10-26},
  abstract = {Planning collision-free and smooth joint motion is crucial in robotic applications, such as welding, milling, and laser cutting. Kinematic redundancy exists when a six-axis industrial robot performs five-dimensional tasks, and there are infinite joint configurations for a six-axis industrial robot to realize a cutter location data of the tool path. The robot joint motion can be optimized by taking advantage of the kinematic redundancy, and the collision-free joint motion with minimum joint movement is determined as the optimal. However, most existing redundancy optimization methods do not fully exploit the redundancy of the six-axis industrial robots when they conduct five-dimensional tasks. In this paper, we present an optimization method to solve the problem of inverse kinematics for a six-axis industrial robot to synthesize the joint motion that follows a given tool path, while achieving smoothness and collision-free manipulation. B-spline is applied for the joint configuration interpolation, and the sum of the squares of the first, second, and third derivatives of the B-spline curves are adopted as the smoothness indicators. Besides, the oriented bounding boxes are adopted to simplify the shape of the robot joints, robot links, spindle unit, and fixtures to facilitate collision detections. Dijkstra's shortest path technique and Differential Evolution algorithm are combined to find the optimal joint motion efficiently and avoid getting into a local optimal solution. The proposed algorithm is validated by simulations on two six-axis industrial robots conducting five-axis flank milling tasks respectively.},
  langid = {english},
  keywords = {Collision-free,Inverse kinematics,Kinematic redundancy,Smooth joint motion},
  file = {/home/julin/Zotero/storage/GJWE4IF3/S073658452030301X.html}
}

@inproceedings{maoLeastSquaresGenerative2017,
  title = {Least {{Squares Generative Adversarial Networks}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Mao, X. and Li, Q. and Xie, H. and Lau, R. Y. K. and Wang, Z. and Smolley, S. P.},
  date = {2017-10},
  pages = {2813--2821},
  issn = {2380-7504},
  doi = {10.1109/ICCV.2017.304},
  abstract = {Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson X2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on LSUN and CIFAR-10 datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  keywords = {classifier,Entropy,Gallium nitride,Generators,higher quality images,image classification,Image resolution,learning process,least squares approximations,Least Squares Generative Adversarial Networks,least squares loss function,Linear programming,LSGANs,Pearson X2 divergence,sigmoid cross entropy loss function,Stability analysis,unsupervised learning,vanishing gradients problem},
  file = {/home/julin/Zotero/storage/E3QJZS5Y/8237566.html}
}

@inproceedings{maraniRealtimeApproachSingularity2002,
  title = {A Real-Time Approach for Singularity Avoidance in Resolved Motion Rate Control of Robotic Manipulators},
  booktitle = {Proceedings 2002 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{Cat}}. {{No}}.{{02CH37292}})},
  author = {Marani, G. and Kim, Jinhyun and Yuh, Junku and Chung, Wan Kyun},
  date = {2002-05},
  volume = {2},
  pages = {1973-1978 vol.2},
  doi = {10.1109/ROBOT.2002.1014830},
  abstract = {In autonomous system, it is important to establish a control scheme that works with stability even near singularity configurations. We describe an online trajectory control scheme that uses the manipulability measure as a distance criteria to avoid manipulator singularities. The proposed approach consists in a method for limiting the minimum value of the distance criteria. The performance is simply affected by the choice of the lower limit. Based on a real-time evaluation of the measure of manipulability, this method does not require a preliminary knowledge of the singular configurations. The proposed algorithm is validated by experimental results.},
  eventtitle = {Proceedings 2002 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{Cat}}. {{No}}.{{02CH37292}})},
  keywords = {Biomechatronics,Control systems,Damping,Jacobian matrices,Kinematics,Laboratories,Manipulators,Motion control,Robot control,Stability},
  file = {/home/julin/Zotero/storage/E4YBTI6D/Marani et al. - 2002 - A real-time approach for singularity avoidance in .pdf;/home/julin/Zotero/storage/BBW6C8R8/1014830.html}
}

@inproceedings{maraniRealtimeApproachSingularity2002a,
  title = {A Real-Time Approach for Singularity Avoidance in Resolved Motion Rate Control of Robotic Manipulators},
  booktitle = {Proceedings 2002 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{Cat}}. {{No}}.{{02CH37292}})},
  author = {Marani, G. and Kim, Jinhyun and Yuh, Junku and Chung, Wan Kyun},
  date = {2002-05},
  volume = {2},
  pages = {1973-1978 vol.2},
  doi = {10.1109/ROBOT.2002.1014830},
  abstract = {In autonomous system, it is important to establish a control scheme that works with stability even near singularity configurations. We describe an online trajectory control scheme that uses the manipulability measure as a distance criteria to avoid manipulator singularities. The proposed approach consists in a method for limiting the minimum value of the distance criteria. The performance is simply affected by the choice of the lower limit. Based on a real-time evaluation of the measure of manipulability, this method does not require a preliminary knowledge of the singular configurations. The proposed algorithm is validated by experimental results.},
  eventtitle = {Proceedings 2002 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{Cat}}. {{No}}.{{02CH37292}})},
  keywords = {Biomechatronics,Control systems,Damping,Jacobian matrices,Kinematics,Laboratories,Manipulators,Motion control,Robot control,Stability},
  file = {/home/julin/Zotero/storage/2Y4K2S4F/1014830.html}
}

@incollection{mashhoodProgrammingAxisArticulated2022,
  title = {Programming of 6 {{Axis Articulated Robot}} for {{Industrial Applications}}},
  booktitle = {Optimization of {{Industrial Systems}}},
  author = {Mashhood, Huzefa and Ali, Mohammed},
  date = {2022},
  pages = {519--532},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781119755074.ch40},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119755074.ch40},
  urldate = {2022-10-23},
  abstract = {Robots are being used as a material handling system and they form a vital part of a flexible manufacturing system. Robots are very useful for work requiring high accuracy and repeatability. Articulated robots can be as straightforward as a two axis structure or complex with at least ten axes and are typically powered by servo motors. Most industrial robots have four to six axes, with six axes being the most well-known. The aim of this study is to maximize the machine utilization by increasing machine flexibility to increase the level of automation/flexibility. This will ultimately result in reduced operation costs. The programs have been developed for transferring parts to the conveyor, pick-place, and stacking operation for the Aristo 6 Axis Robot using teach mode programming. An optimized robotic movement has also been selected. namely linear point to point movement, spline point to point movement, and corresponding point to point joint movement by observing the possible drawbacks of each mode and subsequently possible effects on the total operational time. Finally, the effect of using the ARISTO Robot for the stacking purpose instead of the operator will be studied by developing the simulation models for both cases on the ARENA simulation software.},
  isbn = {978-1-119-75507-4},
  langid = {english},
  keywords = {A utomation,ARENA simulation software,flexibility,robot,stacking,teach mode programming},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119755074.ch40}
}

@inproceedings{mayorgaSingularitiesAvoidanceMethod1987,
  title = {A Singularities Avoidance Method for the Trajectory Planning of Redundant and Nonredundant Robot Manipulators},
  booktitle = {1987 {{IEEE International Conference}} on {{Robotics}} and {{Automation Proceedings}}},
  author = {Mayorga, R. and Wong, A.},
  date = {1987-03},
  volume = {4},
  pages = {1707--1712},
  doi = {10.1109/ROBOT.1987.1087803},
  abstract = {In this paper, a singularities avoidance method suitable for the trajectory planning of redundant and nonredundant robot manipulators is presented. This method is based on establishing proper bounds for the rate of change of the Jacobian matrix of the transformation between the joints speed and end effector Cartesian speed These bounds are computationally inexpensive and easy to deal with by their conversion into additional constraints for any optimization problem which may be formulated to obtain the local or global optimal control of the robot manipulator. Here, this approach is exemplified for the trajectory planning problem of a particular type of redundant and nonredundant robot manipulators studied under an optimal control problem formulation. For each case, this problem is treated as a minimum energy problem with given kinematics and dynamics and subject to the robot requirements, tasks, and the additional singularities avoidance constraints; resulting in a state constrained continuous optimal control which is solved numerically.},
  eventtitle = {1987 {{IEEE International Conference}} on {{Robotics}} and {{Automation Proceedings}}},
  keywords = {Constraint optimization,End effectors,Jacobian matrices,Manipulator dynamics,Optimal control,Orbital robotics,Path planning,Robot control,Robot kinematics,Trajectory},
  file = {/home/julin/Zotero/storage/4AGDHTMB/Mayorga and Wong - 1987 - A singularities avoidance method for the trajector.pdf;/home/julin/Zotero/storage/T6IGIBXD/1087803.html}
}

@misc{mclaughlanCompositeOverwrappedPressure2011,
  title = {Composite {{Overwrapped Pressure Vessels}} ({{COPV}})},
  author = {McLaughlan, Pat B. and Forth, Scott C. and Grimes-Ledesma, Lorie R.},
  date = {2011-03-01},
  publisher = {{NASA}},
  abstract = {Due to the extensive amount of detailed information that has been published on composite overwrapped pressure vessels (COPVs), this document has been written to serve as a primer for those who desire an elementary knowledge of COPVs and the factors affecting composite safety. In this application, the word "composite" simply refers to a matrix of continuous fibers contained within a resin and wrapped over a pressure barrier to form a vessel for gas or liquid containment. COPVs are currently used at NASA to contain high pressure fluids in propulsion, science experiments, and life support applications. They have a significant weight advantage over all metal vessels but require unique design, manufacturing, and test requirements. COPVs also involve a much more complex mechanical understanding due to the interplay between the composite overwrap and the inner liner. A metallic liner is typically used in a COPV as a fluid permeation barrier. The liner design concepts and requirements have been borrowed from all-metal vessels. However, application of metallic vessel design standards to a very thin liner is not straightforward. Different failure modes exist for COPVs than for all-metal vessels, and understanding of these failure modes is at a much more rudimentary level than for metal vessels.},
  langid = {english},
  file = {/home/julin/Zotero/storage/Y4Q2MLPZ/2011 - Composite Overwrapped Pressure Vessels (COPV).pdf}
}

@unpublished{mirzaConditionalGenerativeAdversarial2014,
  title = {Conditional {{Generative Adversarial Nets}}},
  author = {Mirza, Mehdi and Osindero, Simon},
  date = {2014-11-06},
  eprint = {1411.1784},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/julin/Zotero/storage/G8LWM5EI/Mirza und Osindero - 2014 - Conditional Generative Adversarial Nets.pdf;/home/julin/Zotero/storage/7SSQZNR8/1411.html}
}

@inproceedings{miyazakiReinforcementLearningPenalty2000,
  title = {Reinforcement Learning for Penalty Avoiding Policy Making},
  booktitle = {Smc 2000 Conference Proceedings. 2000 Ieee International Conference on Systems, Man and Cybernetics. 'cybernetics Evolving to Systems, Humans, Organizations, and Their Complex Interactions' (Cat. No.0},
  author = {Miyazaki, K. and Kobayashi, S.},
  date = {2000-10},
  volume = {1},
  pages = {206-211 vol.1},
  issn = {1062-922X},
  doi = {10.1109/ICSMC.2000.884990},
  abstract = {Reinforcement learning is a kind of machine learning. It aims to adapt an agent to a given environment with a clue to a reward. In general, the purpose of a reinforcement learning system is to acquire an optimum policy that can maximize expected reward per action. However, it is not always important for any environment. Especially, if we apply reinforcement learning to engineering, we expect the agent to avoid all penalties. In Markov decision processes, we call a rule penalty if and only if it has a penalty or it can transit to a penalty state where it does not contribute to get any reward. After suppressing all penalty rules, we aim to make a rational policy whose expected reward per action is larger than zero. We propose the penalty avoiding rational policy making algorithm that can suppress any penalty as stable as possible and get a reward constantly. By applying the algorithm to the tick-tack-toe its effectiveness is shown.},
  eventtitle = {Smc 2000 Conference Proceedings. 2000 Ieee International Conference on Systems, Man and Cybernetics. 'cybernetics Evolving to Systems, Humans, Organizations, and Their Complex Interactions' (Cat. No.0},
  keywords = {Learning},
  file = {/home/julin/Zotero/storage/HQKMJ3VS/Miyazaki und Kobayashi - 2000 - Reinforcement learning for penalty avoiding policy.pdf;/home/julin/Zotero/storage/4CY3L2UQ/884990.html}
}

@misc{mnihAsynchronousMethodsDeep2016,
  title = {Asynchronous {{Methods}} for {{Deep Reinforcement Learning}}},
  author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  date = {2016-06-16},
  number = {arXiv:1602.01783},
  eprint = {1602.01783},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1602.01783},
  url = {http://arxiv.org/abs/1602.01783},
  urldate = {2022-12-03},
  abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/julin/Zotero/storage/I8B9IEBJ/Mnih et al. - 2016 - Asynchronous Methods for Deep Reinforcement Learni.pdf;/home/julin/Zotero/storage/ZYVIFHIM/1602.html}
}

@article{mnihPlayingAtariDeep,
  title = {Playing {{Atari}} with {{Deep Reinforcement Learning}}},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  pages = {9},
  abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
  langid = {english},
  file = {/home/julin/Zotero/storage/6K8NN6CH/Mnih et al. - Playing Atari with Deep Reinforcement Learning.pdf}
}

@misc{mnihPlayingAtariDeep2013,
  title = {Playing {{Atari}} with {{Deep Reinforcement Learning}}},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  date = {2013-12-19},
  number = {arXiv:1312.5602},
  eprint = {1312.5602},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1312.5602},
  url = {http://arxiv.org/abs/1312.5602},
  urldate = {2022-11-24},
  abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/julin/Zotero/storage/9URX84BU/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf;/home/julin/Zotero/storage/7DS8KE9H/1312.html}
}

@misc{moerlandModelbasedReinforcementLearning2022,
  title = {Model-Based {{Reinforcement Learning}}: {{A Survey}}},
  shorttitle = {Model-Based {{Reinforcement Learning}}},
  author = {Moerland, Thomas M. and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M.},
  date = {2022-03-31},
  number = {arXiv:2006.16712},
  eprint = {2006.16712},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.16712},
  url = {http://arxiv.org/abs/2006.16712},
  urldate = {2022-11-04},
  abstract = {Sequential decision making, commonly formalized as Markov Decision Process (MDP) optimization, is a important challenge in artificial intelligence. Two key approaches to this problem are reinforcement learning (RL) and planning. This paper presents a survey of the integration of both fields, better known as model-based reinforcement learning. Model-based RL has two main steps. First, we systematically cover approaches to dynamics model learning, including challenges like dealing with stochasticity, uncertainty, partial observability, and temporal abstraction. Second, we present a systematic categorization of planning-learning integration, including aspects like: where to start planning, what budgets to allocate to planning and real data collection, how to plan, and how to integrate planning in the learning and acting loop. After these two sections, we also discuss implicit model-based RL as an end-to-end alternative for model learning and planning, and we cover the potential benefits of model-based RL. Along the way, the survey also draws connections to several related RL fields, like hierarchical RL and transfer learning. Altogether, the survey presents a broad conceptual overview of the combination of planning and learning for MDP optimization.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/julin/Zotero/storage/K54EA9HP/Moerland et al. - 2022 - Model-based Reinforcement Learning A Survey.pdf;/home/julin/Zotero/storage/QXEZFP38/2006.html}
}

@online{MultiPassGANFluid,
  title = {A {{Multi-Pass GAN}} for {{Fluid Flow Super-Resolution}} – {{Thuerey Group}}},
  url = {https://ge.in.tum.de/publications/2019-multi-pass-gan/},
  urldate = {2020-10-30},
  langid = {american},
  file = {/home/julin/Zotero/storage/PD5Y8BD8/2019-multi-pass-gan.html}
}

@software{musyMarcomusyVedo20222022,
  title = {Marcomusy/Vedo: 2022.0.1},
  shorttitle = {Marcomusy/Vedo},
  author = {Musy, Marco and Jacquenot, Guillaume and Dalmasso, Giovanni and Neoglez and De Bruin, Ruben and Ahinoam Pollack and Claudi, Federico and Codacy Badger and Icemtel and Zhou, Zhi-Qiang and Bane Sullivan and Lerner, Brian and Hrisca, Daniel and Volpatto, Diego and Evan and Schlömer, Nico and RichardScottOZ and Ilorevilo},
  date = {2022-01-12},
  doi = {10.5281/ZENODO.5842090},
  url = {https://zenodo.org/record/5842090},
  urldate = {2022-07-26},
  abstract = {Main changes {$<$}code{$>$}colors.py{$<$}/code{$>$} minor fixes {$<$}code{$>$}cli.py{$<$}/code{$>$} New CLI mode to emulate {$<$}code{$>$}eog{$<$}/code{$>$} for convenient visualization of common format images : {$<$}code{$>$}vedo --eog https://corepetfood.com/files/2019/07/kitten-e1568311742288-1440x900.jpg{$<$}/code{$>$} &lt;code&gt;Press: up/down to modify level (or drag mouse) left/right to modify window m to mirror image t to rotate image by 90 deg k to enhance b&amp;amp;w image s to apply gaussian smoothing S to save image as png h to print this help banner &lt;/code&gt; {$<$}code{$>$}plotter.py{$<$}/code{$>$} added {$<$}code{$>$}enableErase(){$<$}/code{$>$} {$<$}code{$>$}enableRenderer(){$<$}/code{$>$} {$<$}code{$>$}useDepthPeeling(at){$<$}/code{$>$} methods added {$<$}code{$>$}addScaleIndicator(){$<$}/code{$>$} to add to the scene an indicator of absolute size of objects (needs {$<$}code{$>$}settings.useParallelProjection = True{$<$}/code{$>$}) {$<$}code{$>$}pointcloud.py{$<$}/code{$>$} added {$<$}code{$>$}smoothLloyd2D(){$<$}/code{$>$} for smoothing pointclouds in 2D vtkCellLocator seems to have a problem with single cell meshes (\#558), fixed using vtkStaticCellLocator which behaves normally {$<$}code{$>$}shapes.py{$<$}/code{$>$} added {$<$}code{$>$}Line().pattern(){$<$}/code{$>$} to create a dashed line with a user defined pattern. fixed bug in {$<$}code{$>$}Text2D(){$<$}/code{$>$} New/Revised examples: {$<$}code{$>$}examples/basic/shadow2.py{$<$}/code{$>$}},
  organization = {{Zenodo}},
  version = {v2022.0.1}
}

@inproceedings{okellyScalableEndtoEndAutonomous2018,
  title = {Scalable {{End-to-End Autonomous Vehicle Testing}} via {{Rare-event Simulation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {O' Kelly, Matthew and Sinha, Aman and Namkoong, Hongseok and Tedrake, Russ and Duchi, John C},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2018/hash/653c579e3f9ba5c03f2f2f8cf4512b39-Abstract.html},
  urldate = {2022-11-04},
  abstract = {While recent developments in autonomous vehicle (AV) technology highlight substantial progress, we lack tools for rigorous and scalable testing. Real-world testing, the de facto evaluation environment, places the public in danger, and, due to the rare nature of accidents, will require billions of miles in order to statistically validate performance claims. We implement a simulation framework that can test an entire modern autonomous driving system, including, in particular, systems that employ deep-learning perception and control algorithms. Using adaptive importance-sampling methods to accelerate rare-event probability evaluation, we estimate the probability of an accident under a base distribution governing standard traffic behavior. We demonstrate our framework on a highway scenario, accelerating system evaluation by 2-20 times over naive Monte Carlo sampling methods and 10-300P times (where P is the number of processors) over real-world testing.},
  file = {/home/julin/Zotero/storage/ABRPVG4T/O' Kelly et al. - 2018 - Scalable End-to-End Autonomous Vehicle Testing via.pdf}
}

@inproceedings{olabiEnhancedTrajectoryPlanning2010,
  title = {Enhanced Trajectory Planning for Machining with Industrial Six-Axis Robots},
  booktitle = {2010 {{IEEE International Conference}} on {{Industrial Technology}}},
  author = {Olabi, Adel and Bearee, Richard and Nyiri, Eric and Gibaru1, Olivier},
  date = {2010-03},
  pages = {500--506},
  doi = {10.1109/ICIT.2010.5472749},
  abstract = {This paper presents a practical approach to adapt the trajectory planning stage for industrial robots to realize continuous machining operations. Firstly, L1 interpolation is introduced to generate efficiently the tool-paths in the form of shape-preserving quintic splines. Then, the tool-tip feedrate planning in Cartesian space is done using a smooth jerk limited pattern and taking into account the joints kinematics constraints. Experimental validations conducted on a 6-axis industrial robot demonstrate the effectiveness of the proposed methodology of trajectory planning in the context of machining.},
  eventtitle = {2010 {{IEEE International Conference}} on {{Industrial Technology}}},
  keywords = {Aerospace industry,Cutting tools,Electronics industry,Kinematics,Machining,Motion planning,Orbital robotics,Path planning,Service robots,Trajectory},
  file = {/home/julin/Zotero/storage/5LFPDX6V/Olabi et al. - 2010 - Enhanced trajectory planning for machining with in.pdf;/home/julin/Zotero/storage/UI7JYXEW/5472749.html}
}

@misc{quAttackingDeepReinforcement2021,
  title = {Attacking {{Deep Reinforcement Learning-Based Traffic Signal Control Systems}} with {{Colluding Vehicles}}},
  author = {Qu, Ao and Tang, Yihong and Ma, Wei},
  date = {2021-11-04},
  number = {arXiv:2111.02845},
  eprint = {2111.02845},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2111.02845},
  url = {http://arxiv.org/abs/2111.02845},
  urldate = {2022-10-26},
  abstract = {The rapid advancements of Internet of Things (IoT) and artificial intelligence (AI) have catalyzed the development of adaptive traffic signal control systems (ATCS) for smart cities. In particular, deep reinforcement learning (DRL) methods produce the state-of-the-art performance and have great potentials for practical applications. In the existing DRL-based ATCS, the controlled signals collect traffic state information from nearby vehicles, and then optimal actions (e.g., switching phases) can be determined based on the collected information. The DRL models fully "trust" that vehicles are sending the true information to the signals, making the ATCS vulnerable to adversarial attacks with falsified information. In view of this, this paper first time formulates a novel task in which a group of vehicles can cooperatively send falsified information to "cheat" DRL-based ATCS in order to save their total travel time. To solve the proposed task, we develop CollusionVeh, a generic and effective vehicle-colluding framework composed of a road situation encoder, a vehicle interpreter, and a communication mechanism. We employ our method to attack established DRL-based ATCS and demonstrate that the total travel time for the colluding vehicles can be significantly reduced with a reasonable number of learning episodes, and the colluding effect will decrease if the number of colluding vehicles increases. Additionally, insights and suggestions for the real-world deployment of DRL-based ATCS are provided. The research outcomes could help improve the reliability and robustness of the ATCS and better protect the smart mobility systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {/home/julin/Zotero/storage/LI7PFYZS/Qu et al. - 2021 - Attacking Deep Reinforcement Learning-Based Traffi.pdf;/home/julin/Zotero/storage/IB4MRM6J/2111.html}
}

@article{rasmusandersenKinematicsUR52018,
  title = {Kinematics of a {{UR5}}},
  author = {{Rasmus Andersen}},
  date = {2018},
  url = {https://www.coursehero.com/file/87779377/ur5-kinematicspdf/},
  urldate = {2022-11-25},
  abstract = {View ur5\_kinematics.pdf from 16XXX 00 at Carnegie Mellon University. May 31, 2018 Kinematics of a UR5 Rasmus Skovgaard Andersen Aalborg University Contents 1 2 3 4 5 1 Introduction . . . . . . . .},
  langid = {english},
  file = {/home/julin/Zotero/storage/TBDKI24F/ur5_kinematics.pdf;/home/julin/Zotero/storage/V2JRIGWI/ur5-kinematicspdf.html}
}

@article{ReprintMahalanobis19362018,
  title = {Reprint of: {{Mahalanobis}}, {{P}}.{{C}}. (1936) "{{On}} the {{Generalised Distance}} in {{Statistics}}."},
  shorttitle = {Reprint Of},
  date = {2018-12},
  journaltitle = {Sankhya A},
  shortjournal = {Sankhya A},
  volume = {80},
  number = {S1},
  pages = {1--7},
  issn = {0976-836X, 0976-8378},
  doi = {10.1007/s13171-019-00164-5},
  url = {http://link.springer.com/10.1007/s13171-019-00164-5},
  urldate = {2022-11-13},
  langid = {english},
  file = {/home/julin/Zotero/storage/MCP69K4H/Vol02_1936_1_Art05-pcm.pdf}
}

@book{Road2050Report,
  title = {On the {{Road}} toward 2050: {{Report Massachusetts Institute}} of {{Technology Potential}} for {{Substantial Reductions}} in {{Light-Duty Vehicle Energy Use}} and {{Greenhouse Gas Emissions}}.}
}

@online{roccaUnderstandingGenerativeAdversarial2020,
  title = {Understanding {{Generative Adversarial Networks}} ({{GANs}})},
  author = {Rocca, Joseph},
  date = {2020-07-19T09:14:02},
  url = {https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29},
  urldate = {2020-10-30},
  abstract = {Building, step by step, the reasoning that leads to GANs.},
  langid = {english},
  organization = {{Medium}},
  file = {/home/julin/Zotero/storage/785D7ESS/understanding-generative-adversarial-networks-gans-cd6e4651a29.html}
}

@inproceedings{ronnebergerUNetConvolutionalNetworks2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  booktitle = {Medical {{Image Computing}} and {{Computer-Assisted Intervention}} – {{MICCAI}} 2015},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
  date = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {234--241},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-24574-4_28},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  isbn = {978-3-319-24574-4},
  langid = {english},
  keywords = {Convolutional Layer,Data Augmentation,Deep Network,Ground Truth Segmentation,Training Image},
  file = {/home/julin/Zotero/storage/F3DY6C6U/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf}
}

@online{ros.orgUrdfXMLModel,
  title = {Urdf/{{XML}}/Model},
  author = {{ROS.org}},
  url = {http://wiki.ros.org/urdf/XML/model},
  urldate = {2022-12-02},
  file = {/home/julin/Zotero/storage/U7IEZSI7/model.html}
}

@software{ruanoPyTorchSRGAN,
  title = {{{PyTorch-SRGAN}}},
  author = {Ruano, Aitor},
  url = {https://github.com/aitorzip/PyTorch-SRGAN},
  urldate = {2020-10-30},
  abstract = {A modern PyTorch implementation of SRGAN. Contribute to aitorzip/PyTorch-SRGAN development by creating an account on GitHub.},
  file = {/home/julin/Zotero/storage/3UZIW4YW/PyTorch-SRGAN.html}
}

@unpublished{salimansImprovedTechniquesTraining2016,
  title = {Improved {{Techniques}} for {{Training GANs}}},
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  date = {2016-06-10},
  eprint = {1606.03498},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/julin/Zotero/storage/M2V7J3HQ/Salimans et al. - 2016 - Improved Techniques for Training GANs.pdf;/home/julin/Zotero/storage/QNSEVDC6/1606.html}
}

@book{schroederVisualizationToolkit1998,
  title = {The Visualization Toolkit},
  author = {Schroeder, Will and Martin, Ken and Lorensen, Bill},
  date = {1998},
  edition = {2nd ed},
  publisher = {{Prentice Hall PTR}},
  location = {{Upper Saddle River, NJ}},
  isbn = {978-0-13-954694-5},
  pagetotal = {645},
  keywords = {Computer graphics,Object-oriented programming (Computer science)}
}

@inproceedings{sedarReinforcementLearningbasedMisbehaviour2021,
  title = {Reinforcement {{Learning-based Misbehaviour Detection}} in {{V2X Scenarios}}},
  booktitle = {2021 {{IEEE International Mediterranean Conference}} on {{Communications}} and {{Networking}} ({{MeditCom}})},
  author = {Sedar, Roshan and Kalalas, Charalampos and Vázquez-Gallego, Francisco and Alonso-Zarate, Jesus},
  date = {2021-09},
  pages = {109--111},
  doi = {10.1109/MeditCom49071.2021.9647514},
  abstract = {Emerging vehicle-to-everything (V2X) services rely on the secure exchange of periodic messages between vehicles and between vehicles and infrastructure. However, transmission of false/incorrect data by malicious vehicles may pose important security perils. Therefore, it is essential to detect safety-threatening erroneous information and mitigate potentially detrimental effects on road users. In this paper, we assess the effectiveness of a reinforcement learning (RL) approach for misbehaviour detection in V2X scenarios using an open-source dataset. Considering the case of sudden-stop attacks, the performance of RL-based detection is evaluated over commonly used detection metrics. Our research outcomes reveal that misbehaving vehicles can be accurately detected by exploiting real-time position and speed patterns.},
  eventtitle = {2021 {{IEEE International Mediterranean Conference}} on {{Communications}} and {{Networking}} ({{MeditCom}})},
  keywords = {Analytical models,Conferences,Detectors,Measurement,Misbehaviour Detection,Real-time systems,Reinforcement learning,Reinforcement Learning,Roads,V2X},
  file = {/home/julin/Zotero/storage/3PAS3F8H/Sedar et al. - 2021 - Reinforcement Learning-based Misbehaviour Detectio.pdf;/home/julin/Zotero/storage/HDC6ANLM/9647514.html}
}

@software{shinNashoryGansawesomeapplications2020,
  title = {Nashory/Gans-Awesome-Applications},
  author = {Shin, Minchul},
  date = {2020-10-30T11:31:32Z},
  origdate = {2017-10-12T03:19:02Z},
  url = {https://github.com/nashory/gans-awesome-applications},
  urldate = {2020-10-30},
  abstract = {Curated list of awesome GAN applications and demo. Contribute to nashory/gans-awesome-applications development by creating an account on GitHub.},
  keywords = {applications,curated-list,demonstration,generative-adversarial-network,github,papers}
}

@article{shiObstacleAvoidancePath2022,
  title = {Obstacle {{Avoidance Path Planning}} for the {{Dual-Arm Robot Based}} on an {{Improved RRT Algorithm}}},
  author = {Shi, Wubin and Wang, Ke and Zhao, Chong and Tian, Mengqi},
  date = {2022-01},
  journaltitle = {Applied Sciences},
  volume = {12},
  number = {8},
  pages = {4087},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3417},
  doi = {10.3390/app12084087},
  url = {https://www.mdpi.com/2076-3417/12/8/4087},
  urldate = {2022-11-14},
  abstract = {In the future of automated production processes, the manipulator must be more efficient to complete certain tasks. Compared to single-arm robots, dual-arm robots have a larger workspace and stronger load capacity. Coordinated motion planning of multi-arm robots is a problem that must be solved in the process of robot development. This paper proposes an obstacle avoidance path planning method for the dual-arm robot based on the goal probability bias and cost function in a rapidly-exploring random tree algorithm (GA\_RRT). The random tree grows to the goal point with a certain probability. At the same time, the cost function is calculated when the random state is generated. The point with the lowest cost is selected as the child node. This reduces the randomness and blindness of the RRT algorithm in the expansion process. The detection algorithm of the bounding sphere is used in the process of collision detection of two arms. The main arm conducts obstacle avoidance path planning for static obstacles. The slave arm not only considers static obstacles, but also takes on the role of the main arm at each moment as a dynamic obstacle for path planning. Finally, MATLAB is used for algorithm simulation, which proves the effectiveness of the algorithm for obstacle avoidance path planning problems for the dual-arm robot.},
  issue = {8},
  langid = {english},
  keywords = {autonomous obstacle avoidance,dual-arm robot,improved RRT algorithm,path planning},
  file = {/home/julin/Zotero/storage/Z2QRKRX6/Shi et al. - 2022 - Obstacle Avoidance Path Planning for the Dual-Arm .pdf;/home/julin/Zotero/storage/CWHAIQ46/htm.html}
}

@inproceedings{shohamMultiAgentReinforcementLearning2003,
  title = {Multi-{{Agent Reinforcement Learning}}: A Critical Survey},
  author = {Shoham, Yoav and Powers, Rob and Grenager, Trond},
  date = {2003},
  pages = {13},
  location = {{Stanford CA}},
  abstract = {We survey the recent work in AI on multi-agent reinforcement learning (that is, learning in stochastic games). We then argue that, while exciting, this work is flawed. The fundamental flaw is unclarity about the problem or problems being addressed. After tracing a representative sample of the recent literature, we identify four well-defined problems in multi-agent reinforcement learning, single out the problem that in our view is most suitable for AI, and make some remarks about how we believe progress is to be made on this problem.},
  eventtitle = {Computer {{Science Department Stanford University}}},
  langid = {english},
  file = {/home/julin/Zotero/storage/3T7ZT2PI/Shoham et al. - Multi-Agent Reinforcement Learning a critical sur.pdf}
}

@article{silverMasteringGameGo2016,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  options = {useprefix=true},
  date = {2016-01},
  journaltitle = {Nature},
  volume = {529},
  number = {7587},
  pages = {484--489},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature16961},
  url = {https://www.nature.com/articles/nature16961%7D},
  urldate = {2022-12-05},
  abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
  issue = {7587},
  langid = {english},
  keywords = {Computational science,Computer science,Reward},
  file = {/home/julin/Zotero/storage/DJYNJLCM/Silver et al. - 2016 - Mastering the game of Go with deep neural networks.pdf;/home/julin/Zotero/storage/7HDZC75T/nature16961 .html}
}

@inproceedings{simonstieberRealtimeProcessMonitoring2020,
  title = {Towards {{Real-time Process Monitoring}} and {{Machine Learning}} for {{Manufacturing Composite Structures}}},
  booktitle = {2020 25th {{IEEE International Conference}} on {{Emerging Technologies}} and {{Factory Automation}} ({{ETFA}})},
  author = {{Simon Stieber} and Hoffmann, A. and Schiendorfer, A. and Reif, W. and Beyrle, M. and Faber, J. and Richter, M. and Sause, M.},
  date = {2020-09},
  volume = {1},
  pages = {1455--1458},
  issn = {1946-0759},
  doi = {10.1109/ETFA46521.2020.9212097},
  abstract = {Components made from carbon fiber reinforced plastics (CFRP) offer attractive stability properties for the automotive or aerospace industry despite their light weight. To automate CFRP production, resin transfer molding (RTM) based on thermoset plastics is commonly applied. However, this manufacturing process has its shortcomings in quality and costs. The project CosiMo aims for a highly automated and cost-attractive manufacturing process using cheaper thermoplastic materials. In a thermoplastic RTM (T-RTM) process, the polymerization of ϵ-caprolactam to polyamide 6 is investigated using an intelligent mold tooling. Multiple sensor types integrated into the mold allow for tracking of process-relevant variables, such as material flow and polymerization state. In addition to monitoring the T-RTM process, a digital twin visualizes progress and makes predictions about issues and countermeasures based on machine learning.},
  eventtitle = {2020 25th {{IEEE International Conference}} on {{Emerging Technologies}} and {{Factory Automation}} ({{ETFA}})},
  file = {/home/julin/Zotero/storage/WGP9TVD7/Stieber et al. - 2020 - Towards Real-time Process Monitoring and Machine L.pdf;/home/julin/Zotero/storage/RRRN82F4/9212097.html}
}

@article{stadlerSolutionsExplorationExploitation2014,
  title = {Solutions to the {{Exploration}}/{{Exploitation Dilemma}}: {{Networks}} as a {{New Level}} of {{Analysis}}},
  shorttitle = {Solutions to the {{Exploration}}/{{Exploitation Dilemma}}},
  author = {Stadler, Christian and Rajwani, Tazeeb and Karaba, Florence},
  date = {2014},
  journaltitle = {International Journal of Management Reviews},
  volume = {16},
  number = {2},
  pages = {172--193},
  issn = {1468-2370},
  doi = {10.1111/ijmr.12015},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ijmr.12015},
  urldate = {2022-11-08},
  abstract = {This paper reviews the extant literature on the exploration/exploitation dilemma. Based on a systematic analysis of structural, behavioural, systemic and temporal solutions, the authors are able to show that the learning literature continues to struggle with the question of how exactly an organization can separate exploration and exploitation and at the same time enable necessary knowledge exchange and cooperation between these two notions. Paying closer attention to networks might enable future research to answer this question. In particular, a combination of structural aspects of networks and social ties has the potential to explain how the solutions currently on offer can be implemented successfully, how organizations can combine several of them, and how they can shift between them.},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ijmr.12015},
  file = {/home/julin/Zotero/storage/XBBQIMQC/Stadler et al. - 2014 - Solutions to the ExplorationExploitation Dilemma.pdf;/home/julin/Zotero/storage/6WMB3ECA/ijmr.html}
}

@inproceedings{stieberFlowFrontNetImprovingCarbon2020,
  title = {{{FlowFrontNet}}: {{Improving Carbon Composite Manufacturing}} with {{CNNs}}},
  booktitle = {{{ECML PKDD}}},
  author = {Stieber, Simon and Schroter, Niklas and Schiendorfer, Alexander and Hoffmann, Alwin and Reif, Wolfgang},
  date = {2020},
  pages = {1--17},
  abstract = {Carbon fiber reinforced polymers (CFRP) are light yet strong composite materials designed to reduce the weight of aerospace or automotive components – contributing to reduced emissions. Resin transfer molding (RTM) is a manufacturing process for CFRP that can be scaled up to industrial-sized production. It is prone to errors such as voids or dry spots, resulting in high rejection rates and costs. At runtime, only limited in-process information can be made available for diagnostic insight via a grid of pressure sensors. We propose FlowFrontNet, a deep learning approach to enhance the in-situ process perspective by learning a mapping from sensors to flow front “images” (using upscaling layers), to capture spatial irregularities in the flow front to predict dry spots (using convolutional layers). On simulated data of 6 million single time steps resulting from 36k injection processes, we achieve a time step accuracy of 91.7\% when using a 38 × 30 sensor grid with 1 cm sensor distance in x- and y-direction. On a sensor grid of 10 × 8, with a sensor distance of 4 cm, we achieve 83.7\% accuracy. In both settings, FlowFrontNet provides a significant advantage over direct end-to-end learning models.},
  langid = {english},
  file = {/home/julin/Zotero/storage/58RTYUQI/Stieber et al. - FlowFrontNet Improving Carbon Composite Manufactu.pdf}
}

@inproceedings{stieberTransferLearningOptimization2018,
  title = {Transfer {{Learning}} for {{Optimization}} of {{Carbon Fiber Reinforced Polymer Production}}},
  booktitle = {Organic {{Computing}}: {{Doctoral Dissertation Colloquium}} 2018},
  author = {Stieber, Simon},
  date = {2018-01},
  pages = {1--12},
  url = {https://www.researchgate.net/publication/326423156_Transfer_Learning_for_Optimization_of_Carbon_Fiber_Reinforced_Polymer_Production},
  abstract = {The main problem that keeps many areas of research from using Deep Learning methods is the lack of sufficient amounts of data. We propose transfer learning from simulated data as a solution to that issue. In this work, we present the industrial use case for which we plan to apply our transfer learning approach to: the production of economic Carbon Fiber Reinforced Polymer components. It is currently common practice to draw samples of produced components statistically and perform destructive tests on them, which is very costly. Our goal is to predict the quality of components during the production process. This has the advantage of enabling not only on-line monitoring but also adaptively optimizing the manufacturing procedure. The data comes from sensors embedded in a tooling in a Resin Transfer Molding press.},
  file = {/home/julin/Zotero/storage/N4CQL2M8/Stieber - Transfer Learning for Optimization of Carbon Fiber.pdf}
}

@inproceedings{tekeRealtimeRobustCollaborative2018,
  title = {Real-Time and {{Robust Collaborative Robot Motion Control}} with {{Microsoft Kinect}} ® V2},
  author = {Teke, Burak and Lanz, Minna and Kamarainen, Joni-Kristian and Hietanen, Antti},
  date = {2018-07-01},
  pages = {1--6},
  doi = {10.1109/MESA.2018.8449156},
  file = {/home/julin/Zotero/storage/P7NZ4DVP/Teke et al. - 2018 - Real-time and Robust Collaborative Robot Motion Co.pdf}
}

@online{TempoGANTemporallyCoherent,
  title = {{{tempoGAN}}: {{A Temporally Coherent}}, {{Volumetric GAN}} for {{Super-resolution Fluid Flow}} – {{Thuerey Group}}},
  shorttitle = {{{tempoGAN}}},
  url = {https://ge.in.tum.de/publications/tempogan/},
  urldate = {2020-10-30},
  langid = {american},
  file = {/home/julin/Zotero/storage/ZZCH9UDR/tempogan.html}
}

@online{tokucValueIterationVs2021,
  title = {Value {{Iteration}} vs. {{Policy Iteration}} in {{Reinforcement Learning}} | {{Baeldung}} on {{Computer Science}}},
  author = {Tokuç, A. Aylin},
  date = {2021-07-08T06:45:07+00:00},
  url = {https://www.baeldung.com/cs/ml-value-iteration-vs-policy-iteration},
  urldate = {2022-11-09},
  abstract = {Explore two algorithms to find an optimal policy for an Markov Decision Process.},
  langid = {american},
  file = {/home/julin/Zotero/storage/TXC6PPMU/ml-value-iteration-vs-policy-iteration.html}
}

@online{torres.aiBellmanEquation2021,
  title = {The {{Bellman Equation}}},
  author = {TORRES.AI, Jordi},
  date = {2021-09-24T07:41:58},
  url = {https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7},
  urldate = {2022-11-09},
  abstract = {V-function and Q-function Explained},
  langid = {english},
  organization = {{Medium}},
  file = {/home/julin/Zotero/storage/DBAJ9JBP/the-bellman-equation-59258a0d3fa7.html}
}

@online{UniversalRobotsDH,
  title = {Universal {{Robots}} - {{DH Parameters}} for Calculations of Kinematics and Dynamics},
  url = {https://www.universal-robots.com/articles/ur/application-installation/dh-parameters-for-calculations-of-kinematics-and-dynamics/},
  urldate = {2022-11-24},
  file = {/home/julin/Zotero/storage/F8MYXFRE/dh-parameters-for-calculations-of-kinematics-and-dynamics.html}
}

@online{universalrobotsUniversalRobotsDH,
  title = {Universal {{Robots}} - {{DH Parameters}} for Calculations of Kinematics and Dynamics},
  author = {{Universal Robots}},
  url = {https://www.universal-robots.com/articles/ur/application-installation/dh-parameters-for-calculations-of-kinematics-and-dynamics/},
  urldate = {2022-12-02},
  file = {/home/julin/Zotero/storage/UMLVZ8HI/dh-parameters-for-calculations-of-kinematics-and-dynamics.html}
}

@online{universalrobotsUR5TechnicalSpecifications,
  title = {{{UR5 Technical}} Specifications},
  author = {{Universal Robots}},
  url = {https://www.universal-robots.com/media/50588/ur5_en.pdf},
  urldate = {2022-12-09},
  abstract = {Universal Robots UR5 Technical Specifications},
  file = {/home/julin/Zotero/storage/CMQIWD27/ur5_en.pdf;/home/julin/Zotero/storage/39U2PC7I/www.universal-robots.com.html}
}

@online{UniversalRobotsWhat,
  title = {Universal {{Robots}} - {{What}} Is a Singularity?},
  url = {https://www.universal-robots.com/articles/ur/application-installation/what-is-a-singularity/},
  urldate = {2022-11-14},
  file = {/home/julin/Zotero/storage/HTPJN5A6/what-is-a-singularity.html}
}

@misc{vanhasseltDeepReinforcementLearning2015,
  title = {Deep {{Reinforcement Learning}} with {{Double Q-learning}}},
  author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
  options = {useprefix=true},
  date = {2015-12-08},
  number = {arXiv:1509.06461},
  eprint = {1509.06461},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1509.06461},
  urldate = {2022-11-24},
  abstract = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/julin/Zotero/storage/RWPXN4WD/van Hasselt et al. - 2015 - Deep Reinforcement Learning with Double Q-learning.pdf;/home/julin/Zotero/storage/YSAAAUYX/1509.html}
}

@inproceedings{wangDuelingNetworkArchitectures2016,
  title = {Dueling {{Network Architectures}} for {{Deep Reinforcement Learning}}},
  booktitle = {Proceedings of {{The}} 33rd {{International Conference}} on {{Machine Learning}}},
  author = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  date = {2016-06-11},
  pages = {1995--2003},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v48/wangf16.html},
  urldate = {2022-11-24},
  abstract = {In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/home/julin/Zotero/storage/RTKZD9XM/Wang et al. - 2016 - Dueling Network Architectures for Deep Reinforceme.pdf}
}

@unpublished{wangESRGANEnhancedSuperResolution2018,
  title = {{{ESRGAN}}: {{Enhanced Super-Resolution Generative Adversarial Networks}}},
  shorttitle = {{{ESRGAN}}},
  author = {Wang, Xintao and Yu, Ke and Wu, Shixiang and Gu, Jinjin and Liu, Yihao and Dong, Chao and Loy, Chen Change and Qiao, Yu and Tang, Xiaoou},
  date = {2018-09-17},
  eprint = {1809.00219},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at https://github.com/xinntao/ESRGAN .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/julin/Zotero/storage/ASKP9CGC/Wang et al. - 2018 - ESRGAN Enhanced Super-Resolution Generative Adver.pdf;/home/julin/Zotero/storage/GQX4FGTH/1809.html}
}

@inproceedings{wangFalsificationBasedRobustAdversarial2020,
  title = {Falsification-{{Based Robust Adversarial Reinforcement Learning}}},
  booktitle = {2020 19th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  author = {Wang, Xiao and Nair, Saasha and Althoff, Matthias},
  date = {2020-12},
  pages = {205--212},
  doi = {10.1109/ICMLA51294.2020.00042},
  abstract = {Reinforcement learning (RL) has achieved enormous progress in solving various sequential decision-making problems, such as control tasks in robotics. Since policies are overfitted to training environments, RL methods have often failed to be generalized to safety-critical test scenarios. Robust adversarial RL (RARL) was previously proposed to train an adversarial network that applies disturbances to a system, which improves the robustness in test scenarios. However, an issue of neural network-based adversaries is that integrating system requirements without handcrafting sophisticated reward signals are difficult. Safety falsification methods allow one to find a set of initial conditions and an input sequence, such that the system violates a given property formulated in temporal logic. In this paper, we propose falsification-based RARL (FRARL): this is the first generic framework for integrating temporal logic falsification in adversarial learning to improve policy robustness. By applying our falsification method, we do not need to construct an extra reward function for the adversary. Moreover, we evaluate our approach on a braking assistance system and an adaptive cruise control system of autonomous vehicles. Our experimental results demonstrate that policies trained with a falsification-based adversary generalize better and show less violation of the safety specification in test scenarios than those trained without an adversary or with an adversarial network.},
  eventtitle = {2020 19th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  keywords = {adversarial learning,autonomous driving,formal methods,Measurement,Reinforcement learning,Robots,Robustness,Safety,safety falsification,Task analysis,Training},
  file = {/home/julin/Zotero/storage/APMBB8FF/Wang et al. - 2020 - Falsification-Based Robust Adversarial Reinforceme.pdf;/home/julin/Zotero/storage/E4I3RU4F/9356314.html}
}

@online{wangMonteCarloTree2021,
  title = {Monte {{Carlo Tree Search}}: {{An Introduction}}},
  shorttitle = {Monte {{Carlo Tree Search}}},
  author = {Wang, Benjamin},
  date = {2021-01-11T18:40:34},
  url = {https://towardsdatascience.com/monte-carlo-tree-search-an-introduction-503d8c04e168},
  urldate = {2022-12-05},
  abstract = {MCTS is the cornerstone of AlphaGo and many AI applications. We aim to build some intuitions and along the way get our hands dirty.},
  langid = {english},
  organization = {{Medium}},
  file = {/home/julin/Zotero/storage/MA6BG7ZS/monte-carlo-tree-search-an-introduction-503d8c04e168.html}
}

@article{wangPathPlanningManipulator2022,
  title = {Path Planning of Manipulator Based on Improved {{RRT}} Algorithm},
  author = {Wang, YuYu and Tian, JunCheng and Liu, Zhe and Liu, HaoBo and Liu, JiaZheng and Xie, Lin},
  date = {2022-03-01},
  journaltitle = {Journal of Physics: Conference Series},
  shortjournal = {J. Phys.: Conf. Ser.},
  volume = {2216},
  number = {1},
  pages = {012012},
  issn = {1742-6588, 1742-6596},
  doi = {10.1088/1742-6596/2216/1/012012},
  url = {https://iopscience.iop.org/article/10.1088/1742-6596/2216/1/012012},
  urldate = {2022-11-14},
  abstract = {Aiming at the problem that the 6-DOF manipulator can quickly avoid obstacles in high-dimensional space, the method of path planning based on the improved rapid expansion random tree (RRT) algorithm is proposed. The improved RRT algorithm combines the advantages of the target bias strategy and proposes a method for setting the intermediate bias point. In random sampling, the sampling point is biased to the intermediate bias point,with a certain probability to reduce the blindness of sampling , and use at the same time the path shortening method reduces path nodes and turning points, and optimizes the motion path of the robotic arm. By comparing the simulation results with the RRT and P-RRT algorithms, the effectiveness of the improved RRT algorithm in the calculation time and the number of path nodes is proved.},
  langid = {english},
  file = {/home/julin/Zotero/storage/B6AGM44R/Wang et al. - 2022 - Path planning of manipulator based on improved RRT.pdf}
}

@article{wangPathPlanningManipulator2022a,
  title = {Path Planning of Manipulator Based on Improved {{RRT}} Algorithm},
  author = {Wang, YuYu and Tian, JunCheng and Liu, Zhe and Liu, HaoBo and Liu, JiaZheng and Xie, Lin},
  date = {2022-03},
  journaltitle = {Journal of Physics: Conference Series},
  shortjournal = {J. Phys.: Conf. Ser.},
  volume = {2216},
  number = {1},
  pages = {012012},
  publisher = {{IOP Publishing}},
  issn = {1742-6596},
  doi = {10.1088/1742-6596/2216/1/012012},
  url = {https://dx.doi.org/10.1088/1742-6596/2216/1/012012},
  urldate = {2022-11-14},
  abstract = {Aiming at the problem that the 6-DOF manipulator can quickly avoid obstacles in high-dimensional space, the method of path planning based on the improved rapid expansion random tree (RRT) algorithm is proposed. The improved RRT algorithm combines the advantages of the target bias strategy and proposes a method for setting the intermediate bias point. In random sampling, the sampling point is biased to the intermediate bias point,with a certain probability to reduce the blindness of sampling, and use at the same time the path shortening method reduces path nodes and turning points, and optimizes the motion path of the robotic arm. By comparing the simulation results with the RRT and P-RRT algorithms, the effectiveness of the improved RRT algorithm in the calculation time and the number of path nodes is proved.},
  langid = {english},
  file = {/home/julin/Zotero/storage/SFPCF5TH/Wang et al. - 2022 - Path planning of manipulator based on improved RRT.pdf}
}

@software{wangXinntaoBasicSR2020,
  title = {Xinntao/{{BasicSR}}},
  author = {Wang, Xintao},
  date = {2020-10-30T13:07:46Z},
  origdate = {2018-04-19T18:58:00Z},
  url = {https://github.com/xinntao/BasicSR},
  urldate = {2020-10-30},
  abstract = {Open Source Image and Video Restoration Toolbox, especially for Super-Resolution, including EDSR, RCAN, SRResNet, SRGAN, ESRGAN, EDVR, etc. Also support StyleGAN2, DFDNet.},
  keywords = {basicsr,dfdnet,edsr,edvr,esrgan,pytorch,rcan,restoration,srgan,srresnet,stylegan2,super-resolution}
}

@software{wangXinntaoESRGAN2020,
  title = {Xinntao/{{ESRGAN}}},
  author = {Wang, Xintao},
  date = {2020-10-30T12:30:51Z},
  origdate = {2018-08-31T08:18:41Z},
  url = {https://github.com/xinntao/ESRGAN},
  abstract = {ECCV18 Workshops},
  keywords = {esrgan}
}

@article{watkinsQlearning1992,
  title = {Q-Learning},
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  date = {1992-05-01},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {8},
  number = {3},
  pages = {279--292},
  issn = {1573-0565},
  doi = {10.1007/BF00992698},
  url = {https://doi.org/10.1007/BF00992698},
  urldate = {2022-12-05},
  abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  langid = {english},
  keywords = {asynchronous dynamic programming,Q-learning,reinforcement learning,temporal differences},
  file = {/home/julin/Zotero/storage/PIT77GHZ/Watkins und Dayan - 1992 - Q-learning.pdf}
}

@online{wengPolicyGradientAlgorithms2018,
  title = {Policy {{Gradient Algorithms}}},
  author = {Weng, Lilian},
  date = {2018-04-08T00:00:00+00:00},
  url = {https://lilianweng.github.io/posts/2018-04-08-policy-gradient/},
  urldate = {2022-12-03},
  abstract = {[Updated on 2018-06-30: add two new policy gradient methods, SAC and D4PG.]  [Updated on 2018-09-30: add a new policy gradient method, TD3.]  [Updated on 2019-02-09: add SAC with automatically adjusted temperature].  [Updated on 2019-06-26: Thanks to Chanseok, we have a version of this post in Korean].  [Updated on 2019-09-12: add a new policy gradient method SVPG.]  [Updated on 2019-12-22: add a new policy gradient method IMPALA.},
  langid = {english},
  file = {/home/julin/Zotero/storage/RUNECQ34/2018-04-08-policy-gradient.html}
}

@online{WhatAreL1,
  title = {What {{Are L1}} and {{L2 Loss Functions}}?},
  url = {https://afteracademy.com/blog/what-are-l1-and-l2-loss-functions},
  urldate = {2020-11-17},
  abstract = {L1 and L2 are two loss functions in machine learning which are used to minimize the error.},
  file = {/home/julin/Zotero/storage/X7WY3676/what-are-l1-and-l2-loss-functions.html}
}

@article{whiteSurveyApplicationsMarkov1993,
  title = {A {{Survey}} of {{Applications}} of {{Markov Decision Processes}}},
  author = {White, D. J.},
  date = {1993-11-01},
  journaltitle = {Journal of the Operational Research Society},
  volume = {44},
  number = {11},
  pages = {1073--1096},
  publisher = {{Taylor \& Francis}},
  issn = {0160-5682},
  doi = {10.1057/jors.1993.181},
  url = {https://doi.org/10.1057/jors.1993.181},
  urldate = {2022-10-28},
  abstract = {A collection of papers on the application of Markov decision processes is surveyed and classified according to the use of real life data, structural results and special computational schemes. Observations are made about various features of the applications.},
  keywords = {Applications,Markov Decision Processes},
  annotation = {\_eprint: https://doi.org/10.1057/jors.1993.181}
}

@online{yoonDoubleDeepNetworks2019,
  title = {Double {{Deep Q Networks}}},
  author = {Yoon, Chris},
  date = {2019-07-17T16:29:45},
  url = {https://towardsdatascience.com/double-deep-q-networks-905dd8325412},
  urldate = {2022-11-24},
  abstract = {Tackling maximization bias in Deep Q-learning},
  langid = {english},
  organization = {{Medium}},
  file = {/home/julin/Zotero/storage/LGBCUYET/double-deep-q-networks-905dd8325412.html}
}

@online{yoonDuelingDeepNetworks2019,
  title = {Dueling {{Deep Q Networks}}},
  author = {Yoon, Chris},
  date = {2019-10-20T03:25:20},
  url = {https://towardsdatascience.com/dueling-deep-q-networks-81ffab672751},
  urldate = {2022-11-24},
  abstract = {Dueling Network Architectures for Deep Reinforcement Learning},
  langid = {english},
  organization = {{Medium}},
  file = {/home/julin/Zotero/storage/86Q68MIF/dueling-deep-q-networks-81ffab672751.html}
}

@online{yoonUnderstandingActorCritic2019,
  title = {Understanding {{Actor Critic Methods}}},
  author = {Yoon, Chris},
  date = {2019-07-17T13:51:26},
  url = {https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f},
  urldate = {2022-12-03},
  abstract = {Preliminaries},
  langid = {english},
  organization = {{Medium}},
  file = {/home/julin/Zotero/storage/HULSRT95/understanding-actor-critic-methods-931b97b6df3f.html}
}

@book{zhangDiveDeepLearning2020,
  title = {Dive into {{Deep Learning}}},
  author = {Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
  date = {2020},
  url = {https://d2l.ai},
  urldate = {2020-11-10},
  file = {/home/julin/Zotero/storage/AYBK63TV/index.html}
}

@article{zhangSelfAttentionGenerativeAdversarial,
  title = {Self-{{Attention Generative Adversarial Networks}}},
  author = {Zhang, Han and Goodfellow, Ian and Metaxas, Dimitris and Odena, Augustus},
  pages = {10},
  abstract = {In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN performs better than prior work1, boosting the best published Inception score from 36.8 to 52.52 and reducing Fre´chet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.},
  langid = {english},
  file = {/home/julin/Zotero/storage/8AATFX2U/Zhang et al. - Self-Attention Generative Adversarial Networks.pdf}
}

@incollection{zhuMultimodalImagetoImageTranslation2017,
  title = {Toward {{Multimodal Image-to-Image Translation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30},
  author = {Zhu, Jun-Yan and Zhang, Richard and Pathak, Deepak and Darrell, Trevor and Efros, Alexei A and Wang, Oliver and Shechtman, Eli},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  date = {2017},
  pages = {465--476},
  publisher = {{Curran Associates, Inc.}},
  url = {http://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation.pdf},
  file = {/home/julin/Zotero/storage/E5BZTNN8/Zhu et al. - 2017 - Toward Multimodal Image-to-Image Translation.pdf;/home/julin/Zotero/storage/6HHFXYMS/6650-toward-multimodal-image-to-image-translation.html}
}

@software{zhuPytorchCycleGANandpix2pixImagetoImageTranslation,
  title = {Pytorch-{{CycleGAN-and-pix2pix}}: {{Image-to-Image Translation}} in {{PyTorch}}},
  author = {Zhu, Jun-Yan},
  url = {https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix},
  urldate = {2020-10-30},
  file = {/home/julin/Zotero/storage/6H8H8YYQ/pytorch-CycleGAN-and-pix2pix.html}
}

@unpublished{zhuUnpairedImagetoImageTranslation2020,
  title = {Unpaired {{Image-to-Image Translation}} Using {{Cycle-Consistent Adversarial Networks}}},
  author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
  date = {2020-08-24},
  eprint = {1703.10593},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain \$X\$ to a target domain \$Y\$ in the absence of paired examples. Our goal is to learn a mapping \$G: X \textbackslash rightarrow Y\$ such that the distribution of images from \$G(X)\$ is indistinguishable from the distribution \$Y\$ using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping \$F: Y \textbackslash rightarrow X\$ and introduce a cycle consistency loss to push \$F(G(X)) \textbackslash approx X\$ (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/julin/Zotero/storage/HTH4GDWL/Zhu et al. - 2020 - Unpaired Image-to-Image Translation using Cycle-Co.pdf;/home/julin/Zotero/storage/VDZGSI3M/1703.html}
}
